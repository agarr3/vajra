{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "XlNetCapsule.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyO6Po+EngKpvA5fcCE/79Jp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f2e38844b5004b1d91394ba3d5e9448d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2574b88c720f40cb9b8162005c4edf9f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_aaa6bb8f61e84954a03c6f396dafcfdc",
              "IPY_MODEL_178be7a789c34a94b9004661987718cd"
            ]
          }
        },
        "2574b88c720f40cb9b8162005c4edf9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aaa6bb8f61e84954a03c6f396dafcfdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e41440d32686490cbab6ecf20c9349ad",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 798011,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 798011,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d24d462d4803469c86392f76b43c9788"
          }
        },
        "178be7a789c34a94b9004661987718cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a8cdc910198346528c394037e249ed63",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 798k/798k [00:21&lt;00:00, 36.6kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_899cb0c30369496a882800ee0ab23ddd"
          }
        },
        "e41440d32686490cbab6ecf20c9349ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d24d462d4803469c86392f76b43c9788": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a8cdc910198346528c394037e249ed63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "899cb0c30369496a882800ee0ab23ddd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "59f00c1fc4af40e2842af76494812096": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f45b98d6d2ba4c61b518645aee1cd5c4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1e10198e97674ddf9f749218b8397442",
              "IPY_MODEL_141b6c9f9be541c0ba4434362fec9b97"
            ]
          }
        },
        "f45b98d6d2ba4c61b518645aee1cd5c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1e10198e97674ddf9f749218b8397442": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6827629b82e74949b5e7e1f4c2a5a90c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1382015,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1382015,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4e57aa4146a54a6cb66b4dc8a8c2bedb"
          }
        },
        "141b6c9f9be541c0ba4434362fec9b97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7fcc87bfa71b4714915f4f914d14539b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.38M/1.38M [00:10&lt;00:00, 135kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_369b880a39194681a8a499d94e1b0573"
          }
        },
        "6827629b82e74949b5e7e1f4c2a5a90c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4e57aa4146a54a6cb66b4dc8a8c2bedb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7fcc87bfa71b4714915f4f914d14539b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "369b880a39194681a8a499d94e1b0573": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agarr3/vajra/blob/master/XlNetCapsule.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNVRhonwRLUm",
        "outputId": "a9edbd6b-6a93-4ebf-e5df-c427a44d07af"
      },
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "    process = psutil.Process(os.getpid())\n",
        "    print(\"Gen RAM Free: \" + humanize.naturalsize(psutil.virtual_memory().available), \" |     Proc size: \" + humanize.naturalsize(process.memory_info().rss))\n",
        "    print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total     {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp37-none-any.whl size=7411 sha256=d4449039140ba390fb85725d82d6675f9ee4921153cfba906f826b833f942584\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.7/dist-packages (0.5.1)\n",
            "Gen RAM Free: 26.3 GB  |     Proc size: 118.4 MB\n",
            "GPU RAM Free: 16280MB | Used: 0MB | Util   0% | Total     16280MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNurW_GC_XdL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "991188c1-6212-49f8-8360-2222ab18698f"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install gensim\n",
        "#!pip install unidecode\n",
        "!pip install sentencepiece"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n",
            "\r\u001b[K     |▏                               | 10kB 19.5MB/s eta 0:00:01\r\u001b[K     |▎                               | 20kB 27.9MB/s eta 0:00:01\r\u001b[K     |▍                               | 30kB 26.2MB/s eta 0:00:01\r\u001b[K     |▋                               | 40kB 19.2MB/s eta 0:00:01\r\u001b[K     |▊                               | 51kB 17.0MB/s eta 0:00:01\r\u001b[K     |▉                               | 61kB 12.7MB/s eta 0:00:01\r\u001b[K     |█                               | 71kB 14.1MB/s eta 0:00:01\r\u001b[K     |█▏                              | 81kB 15.2MB/s eta 0:00:01\r\u001b[K     |█▎                              | 92kB 14.6MB/s eta 0:00:01\r\u001b[K     |█▌                              | 102kB 14.3MB/s eta 0:00:01\r\u001b[K     |█▋                              | 112kB 14.3MB/s eta 0:00:01\r\u001b[K     |█▊                              | 122kB 14.3MB/s eta 0:00:01\r\u001b[K     |██                              | 133kB 14.3MB/s eta 0:00:01\r\u001b[K     |██                              | 143kB 14.3MB/s eta 0:00:01\r\u001b[K     |██▏                             | 153kB 14.3MB/s eta 0:00:01\r\u001b[K     |██▎                             | 163kB 14.3MB/s eta 0:00:01\r\u001b[K     |██▌                             | 174kB 14.3MB/s eta 0:00:01\r\u001b[K     |██▋                             | 184kB 14.3MB/s eta 0:00:01\r\u001b[K     |██▊                             | 194kB 14.3MB/s eta 0:00:01\r\u001b[K     |███                             | 204kB 14.3MB/s eta 0:00:01\r\u001b[K     |███                             | 215kB 14.3MB/s eta 0:00:01\r\u001b[K     |███▏                            | 225kB 14.3MB/s eta 0:00:01\r\u001b[K     |███▍                            | 235kB 14.3MB/s eta 0:00:01\r\u001b[K     |███▌                            | 245kB 14.3MB/s eta 0:00:01\r\u001b[K     |███▋                            | 256kB 14.3MB/s eta 0:00:01\r\u001b[K     |███▉                            | 266kB 14.3MB/s eta 0:00:01\r\u001b[K     |████                            | 276kB 14.3MB/s eta 0:00:01\r\u001b[K     |████                            | 286kB 14.3MB/s eta 0:00:01\r\u001b[K     |████▎                           | 296kB 14.3MB/s eta 0:00:01\r\u001b[K     |████▍                           | 307kB 14.3MB/s eta 0:00:01\r\u001b[K     |████▌                           | 317kB 14.3MB/s eta 0:00:01\r\u001b[K     |████▋                           | 327kB 14.3MB/s eta 0:00:01\r\u001b[K     |████▉                           | 337kB 14.3MB/s eta 0:00:01\r\u001b[K     |█████                           | 348kB 14.3MB/s eta 0:00:01\r\u001b[K     |█████                           | 358kB 14.3MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 368kB 14.3MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 378kB 14.3MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 389kB 14.3MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 399kB 14.3MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 409kB 14.3MB/s eta 0:00:01\r\u001b[K     |██████                          | 419kB 14.3MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 430kB 14.3MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 440kB 14.3MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 450kB 14.3MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 460kB 14.3MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 471kB 14.3MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 481kB 14.3MB/s eta 0:00:01\r\u001b[K     |███████                         | 491kB 14.3MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 501kB 14.3MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 512kB 14.3MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 522kB 14.3MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 532kB 14.3MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 542kB 14.3MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 552kB 14.3MB/s eta 0:00:01\r\u001b[K     |████████                        | 563kB 14.3MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 573kB 14.3MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 583kB 14.3MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 593kB 14.3MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 604kB 14.3MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 614kB 14.3MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 624kB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████                       | 634kB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 645kB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 655kB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 665kB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 675kB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 686kB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████                      | 696kB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████                      | 706kB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 716kB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 727kB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 737kB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 747kB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 757kB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████                     | 768kB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████                     | 778kB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 788kB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 798kB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 808kB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 819kB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 829kB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████                    | 839kB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████                    | 849kB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 860kB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 870kB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 880kB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 890kB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 901kB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 911kB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 921kB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 931kB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 942kB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 952kB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 962kB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 972kB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 983kB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 993kB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 1.0MB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 1.0MB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 1.0MB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 1.0MB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 1.0MB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 1.1MB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 1.1MB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 1.1MB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 1.1MB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 1.1MB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 1.1MB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 1.1MB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████                | 1.1MB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 1.1MB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 1.1MB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 1.2MB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 1.2MB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 1.2MB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.2MB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.2MB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 1.2MB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 1.2MB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 1.2MB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 1.2MB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 1.2MB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.3MB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.3MB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 1.3MB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 1.3MB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.3MB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 1.3MB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 1.3MB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.3MB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.3MB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 1.4MB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.4MB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 1.4MB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 1.4MB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 1.4MB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.4MB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.4MB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 1.4MB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 1.4MB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.4MB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.5MB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 1.5MB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.5MB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 1.5MB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.5MB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.5MB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.5MB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.5MB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.5MB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.5MB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.6MB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.6MB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.6MB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.6MB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.6MB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.6MB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.6MB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.6MB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.6MB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.6MB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.7MB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.7MB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.7MB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.7MB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.7MB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.7MB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.7MB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.7MB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.7MB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.8MB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.8MB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.8MB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.8MB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.8MB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.8MB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.8MB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.8MB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.8MB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.8MB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.9MB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.9MB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.9MB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.9MB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.9MB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.9MB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.9MB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.9MB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.9MB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.9MB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 2.0MB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 2.0MB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 2.0MB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 2.0MB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 2.0MB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 2.0MB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 2.0MB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 2.0MB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 2.0MB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 2.0MB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 2.1MB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 2.1MB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 2.1MB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 2.1MB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 2.1MB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 2.1MB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 2.1MB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 2.1MB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 2.1MB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 2.2MB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 2.2MB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 2.2MB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 2.2MB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 2.2MB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 2.2MB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 2.2MB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 2.2MB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 2.2MB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.2MB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.3MB 14.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Collecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 51.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 60.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: huggingface-hub, tokenizers, sacremoses, transformers\n",
            "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.6.1\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.0.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 14.3MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdWsZS1sHBZR"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "\n",
        "class EarlyStoppingAndCheckPointer:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "\n",
        "    def __init__(self, patience=7, verbose=False, delta=0, basedir='.', trace_func=print, epoch_level_save=False):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement.\n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "            path (str): Path for the checkpoint to be saved to.\n",
        "                            Default: 'checkpoint.pt'\n",
        "            trace_func (function): trace print function.\n",
        "                            Default: print\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.basedir = basedir\n",
        "        self.trace_func = trace_func\n",
        "        self.modelCheckPointer = ModelCheckPointer()\n",
        "        self.epoch_level_save = epoch_level_save\n",
        "\n",
        "    def __call__(self, val_loss, model, optimizer, epoch, scheduler):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.modelCheckPointer.save_checkpoint({'epoch': epoch + 1,\n",
        "                               'state_dict': model.state_dict(),\n",
        "                               'optim_dict' : optimizer.state_dict(),\n",
        "                                'sched_dict' : scheduler.state_dict()},\n",
        "                               is_best=True,\n",
        "                               checkpoint=self.basedir, save_epoch = self.epoch_level_save, epoch=epoch)\n",
        "            self.trace_func(\n",
        "                f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "            self.val_loss_min = val_loss\n",
        "\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            self.modelCheckPointer.save_checkpoint({'epoch': epoch + 1,\n",
        "                                                    'state_dict': model.state_dict(),\n",
        "                                                    'optim_dict': optimizer.state_dict(),\n",
        "                                                    'sched_dict' : scheduler.state_dict()},\n",
        "                                                   is_best=False,\n",
        "                                                   checkpoint=self.basedir, save_epoch = self.epoch_level_save, epoch=epoch)\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "            self.trace_func(\n",
        "                f'Validation loss did not decrease. The patience counter is ({self.counter} ).  Saving model as a resume checkpoint ...')\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.modelCheckPointer.save_checkpoint({'epoch': epoch + 1,\n",
        "                                                    'state_dict': model.state_dict(),\n",
        "                                                    'optim_dict': optimizer.state_dict(),\n",
        "                                                    'sched_dict' : scheduler.state_dict()},\n",
        "                                                   is_best=True,\n",
        "                                                   checkpoint=self.basedir, save_epoch = self.epoch_level_save, epoch=epoch)\n",
        "            self.counter = 0\n",
        "            self.trace_func(\n",
        "                f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "            self.val_loss_min = val_loss\n",
        "\n",
        "    # def save_checkpoint(self, val_loss, model):\n",
        "    #     '''Saves model when validation loss decrease.'''\n",
        "    #     if self.verbose:\n",
        "    #         self.trace_func(\n",
        "    #             f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "    #     torch.save(model.state_dict(), self.basedir)\n",
        "    #     self.val_loss_min = val_loss\n",
        "\n",
        "\n",
        "class ModelCheckPointer:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def save_checkpoint(self, state, is_best, checkpoint,  save_epoch = False, epoch=0):\n",
        "        \"\"\"Saves model and training parameters at checkpoint + 'last.pth.tar'. If is_best==True, also saves\n",
        "        checkpoint + 'best.pth.tar'\n",
        "        Args:\n",
        "            state: (dict) contains model's state_dict, may contain other keys such as epoch, optimizer state_dict\n",
        "            is_best: (bool) True if it is the best model seen till now\n",
        "            checkpoint: (string) folder where parameters are to be saved\n",
        "        \"\"\"\n",
        "        filepath = os.path.join(checkpoint, 'last.pth.tar')\n",
        "        if not os.path.exists(checkpoint):\n",
        "            print(\"Checkpoint Directory does not exist! Making directory {}\".format(checkpoint))\n",
        "            os.mkdirs(checkpoint)\n",
        "        else:\n",
        "            print(\"Checkpoint Directory exists! \")\n",
        "        torch.save(state, filepath)\n",
        "        if is_best:\n",
        "            shutil.copyfile(filepath, os.path.join(checkpoint, 'best.pth.tar'))\n",
        "        if save_epoch:\n",
        "            shutil.copyfile(filepath, os.path.join(checkpoint, 'epoch-{}.pth.tar'.format(epoch)))\n",
        "\n",
        "\n",
        "    def load_checkpoint(self, checkpoint, model, device, optimizer=None, scheduler=None):\n",
        "        \"\"\"Loads model parameters (state_dict) from file_path. If optimizer is provided, loads state_dict of\n",
        "        optimizer assuming it is present in checkpoint.\n",
        "        Args:\n",
        "            checkpoint: (string) filename which needs to be loaded\n",
        "            model: (torch.nn.Module) model for which the parameters are loaded\n",
        "            optimizer: (torch.optim) optional: resume optimizer from checkpoint\n",
        "        \"\"\"\n",
        "        filepath = os.path.join(checkpoint, 'last.pth.tar')\n",
        "        if not os.path.exists(filepath):\n",
        "            raise (\"File doesn't exist {}\".format(filepath))\n",
        "        checkpoint = torch.load(checkpoint)\n",
        "        model.load_state_dict(checkpoint['state_dict'], map_location=device)\n",
        "\n",
        "        if optimizer:\n",
        "            optimizer.load_state_dict(checkpoint['optim_dict'])\n",
        "        if scheduler:\n",
        "            scheduler.load_state_dict(checkpoint['sched_dict'])\n",
        "\n",
        "        return checkpoint['epoch']\n",
        "\n",
        "    def loadBestModel(self,checkpoint, model, device):\n",
        "        filepath = os.path.join(checkpoint, 'best.pth.tar')\n",
        "        if not os.path.exists(filepath):\n",
        "            raise (\"File doesn't exist {}\".format(filepath))\n",
        "        checkpoint = torch.load(filepath, map_location=device)\n",
        "        model.load_state_dict(checkpoint['state_dict'])\n",
        "\n",
        "class CustomLossUtils:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def getL1RegularizationLossTerm(self, model, params=None):\n",
        "        regularization_loss = 0\n",
        "        if params is None:\n",
        "            for param in model.parameters():\n",
        "                regularization_loss += torch.sum(torch.abs(param))\n",
        "        else:\n",
        "            for param in params:\n",
        "                regularization_loss += torch.sum(torch.abs(param))\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "ALPHA = 0.8\n",
        "GAMMA = 2\n",
        "\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True):\n",
        "        super(FocalLoss, self).__init__()\n",
        "\n",
        "    def forward(self, inputs, targets, alpha=ALPHA, gamma=GAMMA, smooth=1):\n",
        "        # comment out if your model contains a sigmoid or equivalent activation layer\n",
        "        inputs = F.sigmoid(inputs)\n",
        "\n",
        "        # flatten label and prediction tensors\n",
        "        inputs = inputs.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "\n",
        "        # first compute binary cross-entropy\n",
        "        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n",
        "        BCE_EXP = torch.exp(-BCE)\n",
        "        focal_loss = alpha * (1 - BCE_EXP) ** gamma * BCE\n",
        "\n",
        "        return focal_loss"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jno8QTjoMFny"
      },
      "source": [
        "\n",
        "from gensim.parsing.preprocessing import preprocess_documents, strip_tags, \\\n",
        "    strip_punctuation, strip_numeric, remove_stopwords, strip_short, stem_text\n",
        "\n",
        "from gensim.parsing.preprocessing import strip_multiple_whitespaces\n",
        "import unicodedata\n",
        "import re\n",
        "\n",
        "def remove_accented_chars(text):\n",
        "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "    return text\n",
        "\n",
        "def remove_special_characters(text, remove_digits=False):\n",
        "    pattern = r'[^a-zA-z0-9\\s]' if not remove_digits else r'[^a-zA-z\\s]'\n",
        "    text = re.sub(pattern, ' ', text)\n",
        "    return text\n",
        "\n",
        "def cleanSingleSentenceWithoutRemovingMeaning(x, minsize=3):\n",
        "    processedx = strip_tags(x)\n",
        "    #processedx = unidecode.unidecode(processedx)\n",
        "    processedx = remove_accented_chars(processedx)\n",
        "    processedx = remove_special_characters(processedx)\n",
        "    processedx = strip_multiple_whitespaces(processedx)\n",
        "    processedx = strip_numeric(processedx)\n",
        "    processedx = strip_short(processedx, minsize=minsize)\n",
        "    return processedx\n",
        "\n",
        "\n",
        "def transformSingle(x):\n",
        "    processedx = strip_tags(x)\n",
        "    processedx = strip_punctuation(processedx)\n",
        "    processedx = strip_multiple_whitespaces(processedx)\n",
        "    processedx = strip_numeric(processedx)\n",
        "    processedx = remove_stopwords(processedx)\n",
        "    processedx = strip_short(processedx)\n",
        "    #processedx = lemmatize_sentence(processedx)\n",
        "    processedx = remove_accented_chars(processedx)\n",
        "    processedx = remove_special_characters(processedx)\n",
        "    return processedx.lower()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oynKt5hEyU3"
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "\n",
        "\n",
        "def squash(inputs, axis=-1):\n",
        "    \"\"\"\n",
        "    The non-linear activation used in Capsule. It drives the length of a large vector to near 1 and small vector to 0\n",
        "    :param inputs: vectors to be squashed\n",
        "    :param axis: the axis to squash\n",
        "    :return: a Tensor with same size as inputs\n",
        "    \"\"\"\n",
        "    norm = torch.norm(inputs, p=2, dim=axis, keepdim=True)\n",
        "    scale = norm**2 / (1 + norm**2) / (norm + 1e-8)\n",
        "    return scale * inputs\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class DenseCapsule(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    The dense capsule layer. It is similar to Dense (FC) layer. Dense layer has `in_num` inputs, each is a scalar, the\n",
        "    output of the neuron from the former layer, and it has `out_num` output neurons. DenseCapsule just expands the\n",
        "    output of the neuron from scalar to vector. So its input size = [None, in_num_caps, in_dim_caps] and output size = \\\n",
        "    [None, out_num_caps, out_dim_caps]. For Dense Layer, in_dim_caps = out_dim_caps = 1.\n",
        "\n",
        "    :param in_num_caps: number of cpasules inputted to this layer\n",
        "    :param in_dim_caps: dimension of input capsules\n",
        "    :param out_num_caps: number of capsules outputted from this layer\n",
        "    :param out_dim_caps: dimension of output capsules\n",
        "    :param routings: number of iterations for the routing algorithm\n",
        "    \"\"\"\n",
        "    def __init__(self, in_num_caps, in_dim_caps, out_num_caps, out_dim_caps, routings=3):\n",
        "        super(DenseCapsule, self).__init__()\n",
        "        self.USE_CUDA = torch.cuda.is_available()\n",
        "        self.in_num_caps = in_num_caps\n",
        "        self.in_dim_caps = in_dim_caps\n",
        "        self.out_num_caps = out_num_caps\n",
        "        self.out_dim_caps = out_dim_caps\n",
        "        self.routings = routings\n",
        "        self.weight = torch.nn.Parameter(0.01 * torch.randn(out_num_caps, in_num_caps, out_dim_caps, in_dim_caps))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x.size=[batch, in_num_caps, in_dim_caps]\n",
        "        # expanded to    [batch, 1,            in_num_caps, in_dim_caps,  1]\n",
        "        # weight.size   =[       out_num_caps, in_num_caps, out_dim_caps, in_dim_caps]\n",
        "        # torch.matmul: [out_dim_caps, in_dim_caps] x [in_dim_caps, 1] -> [out_dim_caps, 1]\n",
        "        # => x_hat.size =[batch, out_num_caps, in_num_caps, out_dim_caps]\n",
        "        x_hat = torch.squeeze(torch.matmul(self.weight, x[:, None, :, :, None]), dim=-1)\n",
        "\n",
        "        # In forward pass, `x_hat_detached` = `x_hat`;\n",
        "        # In backward, no gradient can flow from `x_hat_detached` back to `x_hat`.\n",
        "        x_hat_detached = x_hat.detach()\n",
        "\n",
        "        # The prior for coupling coefficient, initialized as zeros.\n",
        "        # b.size = [batch, out_num_caps, in_num_caps]\n",
        "        if self.USE_CUDA:\n",
        "            b = Variable(torch.zeros(x.size(0), self.out_num_caps, self.in_num_caps)).cuda()\n",
        "        else:\n",
        "            b = Variable(torch.zeros(x.size(0), self.out_num_caps, self.in_num_caps))\n",
        "\n",
        "        assert self.routings > 0, 'The \\'routings\\' should be > 0.'\n",
        "        for i in range(self.routings):\n",
        "            # c.size = [batch, out_num_caps, in_num_caps]\n",
        "            c = F.softmax(b, dim=1)\n",
        "\n",
        "            # At last iteration, use `x_hat` to compute `outputs` in order to backpropagate gradient\n",
        "            if i == self.routings - 1:\n",
        "                # c.size expanded to [batch, out_num_caps, in_num_caps, 1           ]\n",
        "                # x_hat.size     =   [batch, out_num_caps, in_num_caps, out_dim_caps]\n",
        "                # => outputs.size=   [batch, out_num_caps, 1,           out_dim_caps]\n",
        "                outputs = squash(torch.sum(c[:, :, :, None] * x_hat, dim=-2, keepdim=True))\n",
        "                # outputs = squash(torch.matmul(c[:, :, None, :], x_hat))  # alternative way\n",
        "            else:  # Otherwise, use `x_hat_detached` to update `b`. No gradients flow on this path.\n",
        "                outputs = squash(torch.sum(c[:, :, :, None] * x_hat_detached, dim=-2, keepdim=True))\n",
        "                # outputs = squash(torch.matmul(c[:, :, None, :], x_hat_detached))  # alternative way\n",
        "\n",
        "                # outputs.size       =[batch, out_num_caps, 1,           out_dim_caps]\n",
        "                # x_hat_detached.size=[batch, out_num_caps, in_num_caps, out_dim_caps]\n",
        "                # => b.size          =[batch, out_num_caps, in_num_caps]\n",
        "                b = b + torch.sum(outputs * x_hat_detached, dim=-1)\n",
        "\n",
        "        return torch.squeeze(outputs, dim=-2)\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-tKt02t_UHj"
      },
      "source": [
        "import gc\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "\n",
        "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from transformers import LongformerTokenizer, LongformerConfig, get_linear_schedule_with_warmup, BertConfig, \\\n",
        "    BertTokenizer, BertModel, XLNetConfig, XLNetTokenizer, XLNetModel\n",
        "\n",
        "from transformers import BertForMaskedLM\n",
        "\n",
        "import joblib\n",
        "import torch\n",
        "from torch import cuda\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.utils.data.sampler import SequentialSampler\n",
        "from torch.hub import tqdm\n",
        "\n",
        "#from pytorchtools import EarlyStoppingAndCheckPointer, ModelCheckPointer\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from transformers.modeling_utils import SequenceSummary"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAtSRqfi--db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "f2e38844b5004b1d91394ba3d5e9448d",
            "2574b88c720f40cb9b8162005c4edf9f",
            "aaa6bb8f61e84954a03c6f396dafcfdc",
            "178be7a789c34a94b9004661987718cd",
            "e41440d32686490cbab6ecf20c9349ad",
            "d24d462d4803469c86392f76b43c9788",
            "a8cdc910198346528c394037e249ed63",
            "899cb0c30369496a882800ee0ab23ddd",
            "59f00c1fc4af40e2842af76494812096",
            "f45b98d6d2ba4c61b518645aee1cd5c4",
            "1e10198e97674ddf9f749218b8397442",
            "141b6c9f9be541c0ba4434362fec9b97",
            "6827629b82e74949b5e7e1f4c2a5a90c",
            "4e57aa4146a54a6cb66b4dc8a8c2bedb",
            "7fcc87bfa71b4714915f4f914d14539b",
            "369b880a39194681a8a499d94e1b0573"
          ]
        },
        "outputId": "839190f9-ef2e-42cf-8f6a-cf3f13dbbe3d"
      },
      "source": [
        "class BertEnsembleModelConfig:\n",
        "    defaultConfig = XLNetConfig()\n",
        "    model_name = 'xlnet-base-cased'\n",
        "    #model_name = \"xlnet-large-cased\"\n",
        "    labelEncoderFileName = 'labelEncoder_xlnet_mood.sav'\n",
        "    savedModelFileName = 'Bert_Ensemble_Model_v1.pt'\n",
        "    tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n",
        "    if model_name == 'xlnet-base-cased':\n",
        "        MAX_LEN = 1024\n",
        "        TRAIN_BATCH_SIZE = [2, 2, 2, 2, 1, 1, 1, 1, 1]\n",
        "        LERANING_RATE_DECAY_MANUAL = [1, 0.9, 0.9*0.9*0.9, 0.9*0.9*0.9*0.9, 0.9*0.9*0.9*0.9*0.9, 0.9*0.9*0.9*0.9*0.9*0.9, 0.9*0.9*0.9*0.9*0.9*0.9*0.9, 0.9*0.9*0.9*0.9*0.9*0.9*0.9, 0.9*0.9*0.9*0.9*0.9*0.9*0.9*0.9*0.9]\n",
        "        ACCUMULATION_STEPS = 1\n",
        "        PATIENCE = 9\n",
        "        EPOCHS = 9\n",
        "    elif model_name == \"xlnet-large-cased\":\n",
        "        MAX_LEN = 1024\n",
        "        TRAIN_BATCH_SIZE = [1, 1, 1, 1, 1]\n",
        "        LERANING_RATE_DECAY_MANUAL = [1, 0.9, 0.9*0.9*0.9, 0.9*0.9*0.9*0.9, 0.9*0.9*0.9*0.9*0.9]\n",
        "        ACCUMULATION_STEPS = 1\n",
        "        PATIENCE = 3\n",
        "        EPOCHS = 5\n",
        "    MAX_LEN_FILENAME = 20\n",
        "    VALID_BATCH_SIZE = 1\n",
        "    \n",
        "\n",
        "    LEARNING_RATE = 1e-05\n",
        "    \n",
        "    LEARNING_RATE_AUTO_DECAY_FLAG = False\n",
        "    LR_DECAY_MODE = \"EPOCH\"\n",
        "\n",
        "    WEIGHT_DECAY = 0.0\n",
        "    \n",
        "    WARM_UP_RATIO = 0.06\n",
        "    WARM_UP_STEPS = 0\n",
        "    max_grad_norm = None\n",
        "    #LOSS_FN = \"BCEWithLogitsLoss\"\n",
        "    #LOSS_FN = \"CrossEntropyLoss\"\n",
        "    LOSS_FN = \"MarginLoss\"\n",
        "    #BERT_MODEL_OP = \"last_hidden\"\n",
        "    BERT_MODEL_OP = \"CLS\"\n",
        "\n",
        "    VALID_FNAME_LEN_TH = 18\n",
        "    HELD_OUT_VALIDATION = True\n",
        "    CONDITIONAL_TRAINING = False\n",
        "\n",
        "    DETERMINISTIC = True\n",
        "    CAPS_PURE = True\n",
        "    CLASS_LOSS_FN = \"BCEWithLogitsLoss\"\n",
        "    #CLASS_LOSS_FN = \"FocalLoss\"\n",
        "    if CAPS_PURE:\n",
        "        LOSS_FN = \"MarginLoss\"\n",
        "    else:\n",
        "        LOSS_FN = CLASS_LOSS_FN\n",
        "\n",
        "    USE_SEQUENCE_SUMMARY = True\n",
        "    SQUASH_AFTER_TRANSFORMER = True\n",
        "    SOFTMAX_DENSE_LAYER = False\n",
        "    \n",
        "    \n",
        "  "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f2e38844b5004b1d91394ba3d5e9448d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=798011.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "59f00c1fc4af40e2842af76494812096",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1382015.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPmN3ZaG_RI9"
      },
      "source": [
        "class BertEnsembletModel(torch.nn.Module):\n",
        "    '''\n",
        "    classdocs\n",
        "    '''\n",
        "\n",
        "    def __init__(self, num_classes, configuration=None):\n",
        "        super(BertEnsembletModel, self).__init__()\n",
        "        if configuration:\n",
        "            self.configuration = configuration\n",
        "        else:\n",
        "            self.configuration = BertEnsembleModelConfig()\n",
        "        self.bert_model_content = XLNetModel.from_pretrained(self.configuration.model_name, mem_len=1024)\n",
        "\n",
        "        xlNetDefConfig = XLNetConfig.from_pretrained(self.configuration.model_name)\n",
        "        self.sequence_summary = SequenceSummary(xlNetDefConfig)\n",
        "\n",
        "        if self.configuration.USE_SEQUENCE_SUMMARY:\n",
        "            in_num_caps = self.configuration.MAX_LEN + 1\n",
        "        else:\n",
        "            in_num_caps = self.configuration.MAX_LEN\n",
        "\n",
        "        if(self.configuration.model_name == \"xlnet-large-cased\"):\n",
        "            self.digitcaps = DenseCapsule(in_num_caps=in_num_caps,\n",
        "                                          in_dim_caps=1024,\n",
        "                                          out_num_caps=num_classes, out_dim_caps=16,\n",
        "                                          routings=3)\n",
        "        elif (self.configuration.model_name == \"xlnet-base-cased\"):\n",
        "            self.digitcaps = DenseCapsule(in_num_caps=in_num_caps,\n",
        "                                          in_dim_caps=768,\n",
        "                                          out_num_caps=num_classes, out_dim_caps=16,\n",
        "                                          routings=3)\n",
        "\n",
        "        self.dense = torch.nn.Linear(num_classes * 16, num_classes * 16)\n",
        "        self.softmax = torch.nn.Softmax()\n",
        "        self.dropout = torch.nn.Dropout(0.3)\n",
        "        self.classifier = torch.nn.Linear(num_classes * 16, num_classes)\n",
        "\n",
        "    def forward(\n",
        "            self,\n",
        "            input_ids=None,\n",
        "            attention_mask=None,\n",
        "            token_type_ids=None,\n",
        "            position_ids=None,\n",
        "            head_mask=None,\n",
        "            inputs_embeds=None,\n",
        "            class_label=None,\n",
        "            exclusion_mask= None\n",
        "    ):\n",
        "\n",
        "        content_output = self.bert_model_content(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        if exclusion_mask is not None and self.configuration.CONDITIONAL_TRAINING:\n",
        "            content_output = content_output[0] * exclusion_mask[0].unsqueeze(dim=-1)\n",
        "        else:\n",
        "            content_output = content_output[0]\n",
        "\n",
        "        if self.configuration.USE_SEQUENCE_SUMMARY:\n",
        "            output_summary = self.sequence_summary(content_output)\n",
        "            content_output = torch.cat([content_output, output_summary.unsqueeze(dim=1)], dim=1)\n",
        "\n",
        "\n",
        "        if self.configuration.SQUASH_AFTER_TRANSFORMER:\n",
        "            op_bert_ensemble = squash(content_output)\n",
        "        else:\n",
        "            op_bert_ensemble = content_output\n",
        "        \n",
        "        \n",
        "        classvecs = self.digitcaps(op_bert_ensemble)\n",
        "\n",
        "        if self.configuration.CAPS_PURE:\n",
        "            outputs = classvecs.norm(dim=-1)\n",
        "        else:\n",
        "            classvecs_fl = classvecs.view(input_ids.size(0), -1)\n",
        "            if self.configuration.SOFTMAX_DENSE_LAYER:\n",
        "                x = self.softmax(self.dense(classvecs_fl))\n",
        "            else:\n",
        "                x = self.dense(classvecs_fl)\n",
        "            x = self.dropout(x)\n",
        "            outputs = self.classifier(x)\n",
        "\n",
        "        return outputs"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpX1OfB6JTmA"
      },
      "source": [
        "class BertEnsembleClassifier(object):\n",
        "    '''\n",
        "    classdocs\n",
        "    '''\n",
        "\n",
        "    def __init__(self, base_dir, modelOverRideForEval = None,  configuration=None, mode=\"eval\", cross=0):\n",
        "        '''\n",
        "        Constructor\n",
        "        '''\n",
        "        if configuration:\n",
        "            self.configuration = configuration\n",
        "        else:\n",
        "            self.configuration = BertEnsembleModelConfig()\n",
        "        self.BASE_DIR = base_dir\n",
        "        self.labelEncoderPath = os.path.join(self.BASE_DIR, self.configuration.labelEncoderFileName)\n",
        "        self.modelPath = os.path.join(self.BASE_DIR, self.configuration.savedModelFileName)\n",
        "        self.device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "        self.cross = cross\n",
        "\n",
        "        if self.configuration.DETERMINISTIC:\n",
        "            self.seed_everything()\n",
        "\n",
        "        self.tokenizer = self.configuration.tokenizer\n",
        "        if mode == \"eval\":\n",
        "            self.lb = joblib.load(self.labelEncoderPath)\n",
        "            self.model = BertEnsembletModel(len(self.lb.classes_), self.configuration)\n",
        "            if modelOverRideForEval:\n",
        "                self.model.load_state_dict(torch.load(modelOverRideForEval, map_location=self.device))\n",
        "                self.model.eval()\n",
        "            else:\n",
        "                modelCheckpointer = ModelCheckPointer()\n",
        "                modelCheckpointer.loadBestModel(self.BASE_DIR, self.model, self.device)\n",
        "                self.model.eval()\n",
        "        elif mode == \"train\":\n",
        "            self.avg_train_losses = []\n",
        "            self.avg_valid_losses = []\n",
        "            self.train_accuracy_list = []\n",
        "            self.valid_accuracy_list = []\n",
        "            self.LR = []\n",
        "            self.DEBUG_INCORRECT = {}\n",
        "\n",
        "\n",
        "        else:\n",
        "            raise Exception(\"illegal mode\")\n",
        "\n",
        "    def predict(self, content, processed=False):\n",
        "\n",
        "        self.model.eval()\n",
        "        if not processed:\n",
        "            content = cleanSingleSentenceWithoutRemovingMeaning(content)\n",
        "\n",
        "        content = \" \".join(content.split(\" \")[0:self.configuration.MAX_LEN])\n",
        "\n",
        "        with torch.no_grad():\n",
        "            inputs = self.tokenizer.encode_plus(\n",
        "                content,\n",
        "                None,\n",
        "                add_special_tokens=True,\n",
        "                max_length=self.configuration.MAX_LEN,\n",
        "                pad_to_max_length=True,\n",
        "                return_attention_mask=True,\n",
        "                # return_tensors='pt',\n",
        "                truncation=True\n",
        "            )\n",
        "            ids = inputs['input_ids']\n",
        "            mask = inputs['attention_mask']\n",
        "\n",
        "            ids = [ids]\n",
        "            mask = [mask]\n",
        "\n",
        "            contentIds = torch.tensor(ids, dtype=torch.long)\n",
        "            contentMask = torch.tensor(mask, dtype=torch.long)\n",
        "            contenteExclusionMask = torch.ones((1))\n",
        "\n",
        "            inputs = {\n",
        "                \"input_ids\": contentIds,\n",
        "                \"attention_mask\": contentMask,\n",
        "                \"exclusion_mask\": contenteExclusionMask\n",
        "            }\n",
        "\n",
        "            outputs = self.model(**inputs)\n",
        "            prediction = torch.sigmoid(outputs)\n",
        "\n",
        "        return self.lb.inverse_transform(prediction.detach().numpy())\n",
        "\n",
        "    def seed_everything(self, seed=1234):\n",
        "        random.seed(seed)\n",
        "        torch.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        np.random.seed(seed)\n",
        "        os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "\n",
        "    def loss_fn(self, outputs, targets):\n",
        "        if self.configuration.LOSS_FN == \"CrossEntropyLoss\":\n",
        "            torch.nn.CrossEntropyLoss()(outputs, targets)\n",
        "        elif self.configuration.LOSS_FN == \"BCEWithLogitsLoss\":\n",
        "            return torch.nn.BCEWithLogitsLoss()(outputs, targets)\n",
        "        elif self.configuration.LOSS_FN == \"MarginLoss\":\n",
        "            return self.caps_loss(targets, outputs)\n",
        "        elif self.configuration.LOSS_FN == \"FocalLoss\":\n",
        "            return FocalLoss()(outputs, targets)\n",
        "\n",
        "    def caps_loss(self, y_true, y_pred):\n",
        "        \"\"\"\n",
        "        Capsule loss = Margin loss\n",
        "        :param y_true: true labels, one-hot coding, size=[batch, classes]\n",
        "        :param y_pred: predicted labels by CapsNet, size=[batch, classes]\n",
        "        :return: Variable contains a scalar loss value.\n",
        "        \"\"\"\n",
        "        L = y_true * torch.clamp(0.9 - y_pred, min=0.) ** 2 + \\\n",
        "            0.5 * (1 - y_true) * torch.clamp(y_pred - 0.1, min=0.) ** 2\n",
        "        L_margin = L.sum(dim=1).mean()\n",
        "\n",
        "        return L_margin\n",
        "\n",
        "    def run_evaluation(self, model, validation_data_loader_content):\n",
        "        model.eval()\n",
        "        valid_losses = []\n",
        "        accuracyBoolList = []\n",
        "        confusionMatrix = torch.zeros(len(self.lb.classes_), len(self.lb.classes_))\n",
        "        inncorrectPreds = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "          for step, batch in tqdm(enumerate(validation_data_loader_content), desc=\"running evaluation\"):\n",
        "              contentBatch = batch\n",
        "              batch_1 = tuple(t.to(self.device) for t in contentBatch)\n",
        "\n",
        "              targets = batch_1[2]\n",
        "              inputs = {\n",
        "                  \"input_ids\": batch_1[0],\n",
        "                  \"attention_mask\": batch_1[1],\n",
        "                  \"exclusion_mask\": batch_1[3]\n",
        "              }\n",
        "              outputs = model(**inputs)\n",
        "              loss = self.loss_fn(outputs, targets)\n",
        "              valid_losses.append(loss.item())\n",
        "              _, predicted = torch.max(outputs, 1)\n",
        "              _, trueClass = torch.max(targets, 1)\n",
        "              for trueClassLabel, predictedClassLabel in zip(trueClass, predicted):\n",
        "                  confusionMatrix[trueClassLabel, predictedClassLabel] = confusionMatrix[trueClassLabel, predictedClassLabel] +1\n",
        "              booleans = (predicted == trueClass)\n",
        "              accuracyBoolList.extend([boolean.item() for boolean in booleans])\n",
        "              \n",
        "              # print(\"predicted\")\n",
        "              # print(predicted)\n",
        "              # print(trueClass)\n",
        "\n",
        "              \n",
        "              incorrectPredictionIndices = [i for i, x in enumerate(booleans) if not x]\n",
        "              for index in incorrectPredictionIndices:\n",
        "                inncorrectPreds.append(batch_1[0][index].detach().cpu().numpy())\n",
        "                  \n",
        "                  \n",
        "\n",
        "              del outputs, inputs, batch_1\n",
        "              gc.collect()\n",
        "        return valid_losses, accuracyBoolList, confusionMatrix, inncorrectPreds\n",
        "\n",
        "    def run_training(self, epoch, model, training_data_loader_content, optimizer, scheduler):\n",
        "\n",
        "        model.train()\n",
        "        model.zero_grad()\n",
        "        train_losses = []\n",
        "        accuracyBoolList = []\n",
        "        confusionMatrix = torch.zeros(len(self.lb.classes_), len(self.lb.classes_))\n",
        "\n",
        "        for step, batch in tqdm(enumerate(training_data_loader_content), desc=\"running training for epoch {}\".format(epoch)):\n",
        "            contentBatch = batch\n",
        "\n",
        "            batch_1 = tuple(t.to(self.device) for t in contentBatch)\n",
        "\n",
        "            targets = batch_1[2]\n",
        "            inputs = {\n",
        "                \"input_ids\": batch_1[0],\n",
        "                \"attention_mask\": batch_1[1],\n",
        "                \"exclusion_mask\": batch_1[3]\n",
        "            }\n",
        "            outputs = model(**inputs)\n",
        "            loss = self.loss_fn(outputs, targets)\n",
        "            train_losses.append(loss.item())\n",
        "            if self.configuration.ACCUMULATION_STEPS != 1:\n",
        "                loss = loss / self.configuration.ACCUMULATION_STEPS\n",
        "            loss.backward()\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            _, trueClass = torch.max(targets, 1)\n",
        "            for trueClassLabel, predictedClassLabel in zip(trueClass, predicted):\n",
        "                confusionMatrix[trueClassLabel, predictedClassLabel] = confusionMatrix[\n",
        "                                                                           trueClassLabel, predictedClassLabel] + 1\n",
        "            booleans = (predicted == trueClass)\n",
        "            accuracyBoolList.extend([boolean.item() for boolean in booleans])\n",
        "\n",
        "            if (step + 1) % self.configuration.ACCUMULATION_STEPS == 0:\n",
        "                if self.configuration.max_grad_norm is not None:\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), self.configuration.max_grad_norm)\n",
        "                optimizer.step()  # Now we can do an optimizer step\n",
        "                if self.configuration.LR_DECAY_MODE == \"BATCH\" and self.configuration.LEARNING_RATE_AUTO_DECAY_FLAG:\n",
        "                    print(\"Learning rate decay at batch level, reducing LR\")\n",
        "                    scheduler.step()\n",
        "                    self.LR.append(scheduler.get_lr())\n",
        "                #optimizer.zero_grad()\n",
        "                model.zero_grad()\n",
        "                print('Epoch: {}, step: {},  Loss:  {}'.format(epoch, step, loss.item()))\n",
        "\n",
        "\n",
        "            del outputs, inputs, batch_1\n",
        "            gc.collect()\n",
        "        return train_losses, accuracyBoolList, confusionMatrix\n",
        "\n",
        "    def train(self, training_data, testing_data, trainDataSize, trainFromScratch=True):\n",
        "\n",
        "        self.lb = LabelBinarizer()\n",
        "        training_data['labelvec'] = self.lb.fit_transform(training_data['Mood']).tolist()\n",
        "\n",
        "        training_data_content = training_data[['lyrics', 'labelvec']]\n",
        "        training_data_content = training_data_content.rename(columns={\"lyrics\": \"text\"})\n",
        "        joblib.dump(self.lb, self.labelEncoderPath)\n",
        "\n",
        "        testing_data['labelvec'] = self.lb.transform(testing_data['Mood']).tolist()\n",
        "\n",
        "        testingDataContent = testing_data[['lyrics', 'labelvec']]\n",
        "        testingDataContent = testingDataContent.rename(columns={\"lyrics\": \"text\"})\n",
        "\n",
        "        print(\"creatinng dataset. The tokenizer is \", self.tokenizer)\n",
        "        content_training_set = CustomDataset(training_data_content, self.tokenizer, self.configuration.MAX_LEN)\n",
        "        content_testing_set = CustomDataset(testingDataContent, self.tokenizer, self.configuration.MAX_LEN)\n",
        "\n",
        "\n",
        "        content_training_loader = DataLoader(content_training_set,\n",
        "                                             batch_size=self.configuration.TRAIN_BATCH_SIZE[0],\n",
        "                                             sampler=SequentialSampler(content_training_set), drop_last=False)\n",
        "\n",
        "\n",
        "        content_testing_loader = DataLoader(content_testing_set,\n",
        "                                               batch_size=self.configuration.VALID_BATCH_SIZE,\n",
        "                                               sampler=SequentialSampler(content_testing_set), drop_last=False)\n",
        "\n",
        "\n",
        "        model = BertEnsembletModel(len(self.lb.classes_))\n",
        "\n",
        "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "        if self.configuration.WEIGHT_DECAY == 0.0:\n",
        "            print(\"weight decay parameter is 0 so, using no weight decay anywhere\")\n",
        "            optimizer_grouped_parameters = [{\n",
        "                \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "            }]\n",
        "        else:\n",
        "            print(\"weight decay parameter is {} so, using this weight decay anywhere\".format(self.configuration.WEIGHT_DECAY))\n",
        "            optimizer_grouped_parameters = [\n",
        "                {\n",
        "                    \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "                    \"weight_decay\": self.configuration.WEIGHT_DECAY,\n",
        "                },\n",
        "                {\n",
        "                    \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "                    \"weight_decay\": 0.0,\n",
        "                },\n",
        "            ]\n",
        "\n",
        "        if self.configuration.LR_DECAY_MODE == \"BATCH\":\n",
        "            t_total = len(content_training_loader) // self.configuration.ACCUMULATION_STEPS * self.configuration.EPOCHS\n",
        "            print(\"Learning rate decay at batch level, t_total is {}\".format(t_total))\n",
        "        elif self.configuration.LR_DECAY_MODE == \"EPOCH\":\n",
        "            t_total = self.configuration.EPOCHS\n",
        "            print(\"Learning rate decay at epoch level, t_total is {}\".format(t_total))\n",
        "\n",
        "        if self.configuration.WARM_UP_STEPS == None:\n",
        "            warmup_steps = math.ceil(t_total * self.configuration.WARM_UP_RATIO)\n",
        "        else:\n",
        "            warmup_steps = self.configuration.WARM_UP_STEPS\n",
        "        optimizer = torch.optim.AdamW(params=optimizer_grouped_parameters, lr=self.configuration.LEARNING_RATE)\n",
        "        scheduler = get_linear_schedule_with_warmup(\n",
        "            optimizer, num_warmup_steps=warmup_steps, num_training_steps=t_total\n",
        "        )\n",
        "\n",
        "        savedEpoch = 0\n",
        "        if not trainFromScratch:\n",
        "            # PATH = previousSavedModel\n",
        "            modelCheckpointer = ModelCheckPointer()\n",
        "            savedEpoch = modelCheckpointer.load_checkpoint(self.BASE_DIR, model, self.device, optimizer, scheduler)\n",
        "            # model.load_state_dict(torch.load(PATH, map_location=self.device))\n",
        "        model.to(self.device)\n",
        "\n",
        "        early_stopping = EarlyStoppingAndCheckPointer(patience=self.configuration.PATIENCE, verbose=True, basedir=self.BASE_DIR, epoch_level_save=False)\n",
        "\n",
        "        #self.initialLog(model,content_training_loader, content_testing_loader)\n",
        "        for epoch in range(savedEpoch, self.configuration.EPOCHS):\n",
        "            print(\"starting training. The LR is {}\".format(scheduler.get_lr()))\n",
        "\n",
        "            trainBatchSizeForEpoch = self.configuration.TRAIN_BATCH_SIZE[epoch]\n",
        "            if trainBatchSizeForEpoch < 1:\n",
        "                trainBatchSizeForEpoch = 1\n",
        "            content_training_loader = DataLoader(content_training_set,\n",
        "                                                 batch_size=trainBatchSizeForEpoch,\n",
        "                                                 sampler=SequentialSampler(content_training_set), drop_last=False)\n",
        "\n",
        "\n",
        "            if not self.configuration.LEARNING_RATE_AUTO_DECAY_FLAG:\n",
        "                lrForEpoch = self.configuration.LEARNING_RATE * self.configuration.LERANING_RATE_DECAY_MANUAL[epoch]\n",
        "                for param_group in optimizer.param_groups:\n",
        "                    param_group['lr'] = lrForEpoch\n",
        "                    print(\"setting LR manually to {}\".format(lrForEpoch))\n",
        "\n",
        "            train_losses, accuracyBoolListTrain, confusionMatrixTrain = self.run_training(epoch, model, content_training_loader, optimizer, scheduler)\n",
        "            if self.configuration.LR_DECAY_MODE == \"EPOCH\" and self.configuration.LEARNING_RATE_AUTO_DECAY_FLAG:\n",
        "                scheduler.step()\n",
        "                print(\"Learning rate decay at epoch level, reducing LR to {}\".format(scheduler.get_lr()))\n",
        "                self.LR.append(scheduler.get_lr())\n",
        "\n",
        "            valid_losses, accuracyBoolListValid, confusionMatrixValid, inncorrectPreds = self.run_evaluation(model, content_testing_loader)\n",
        "\n",
        "            train_loss = np.average(train_losses)\n",
        "            valid_loss = np.average(valid_losses)\n",
        "            accuracy_train = sum(accuracyBoolListTrain)/len(accuracyBoolListTrain) * 100\n",
        "            accuracy_valid = sum(accuracyBoolListValid) / len(accuracyBoolListValid) * 100\n",
        "\n",
        "            self.avg_train_losses.append(train_loss)\n",
        "            self.avg_valid_losses.append(valid_loss)\n",
        "            self.train_accuracy_list.append(accuracy_train)\n",
        "            self.valid_accuracy_list.append(accuracy_valid)\n",
        "\n",
        "            print('Epoch: {},  Total Train Loss:  {}'.format(epoch+1, train_loss))\n",
        "            print('Epoch: {},  Total Validation Loss:  {}'.format(epoch+1, valid_loss))\n",
        "            print('Epoch: {},  Total training accuracy:  {}'.format(epoch+1, accuracy_train))\n",
        "            print('Epoch: {},  Total Validation accuracy:  {}'.format(epoch+1, accuracy_valid))\n",
        "\n",
        "            early_stopping(valid_loss, model, optimizer, epoch, scheduler)\n",
        "\n",
        "\n",
        "            self.visualizeTraining(epoch+1, confusionMatrixTrain, cross = self.cross)\n",
        "            self.visualizeValAccuracy(epoch+1, confusionMatrixValid, cross = self.cross)\n",
        "            self.visualizeLR(epoch + 1,  cross = self.cross)\n",
        "            if early_stopping.early_stop:\n",
        "                print(\"Early stopping\")\n",
        "                self.model = model\n",
        "                break\n",
        "\n",
        "    def initialLog(self, model,\n",
        "                   content_training_loader,\n",
        "                   content_testing_loader):\n",
        "        train_losses, accuracyBoolListTrain, confusionMatrixTrain = self.run_evaluation(model,content_training_loader)\n",
        "        valid_losses, accuracyBoolListValid, confusionMatrixValid = self.run_evaluation(model,content_testing_loader)\n",
        "\n",
        "        train_loss = np.average(train_losses)\n",
        "        valid_loss = np.average(valid_losses)\n",
        "        accuracy_train = sum(accuracyBoolListTrain) / len(accuracyBoolListTrain) * 100\n",
        "        accuracy_valid = sum(accuracyBoolListValid) / len(accuracyBoolListValid) * 100\n",
        "\n",
        "        self.avg_train_losses.append(train_loss)\n",
        "        self.avg_valid_losses.append(valid_loss)\n",
        "        self.train_accuracy_list.append(accuracy_train)\n",
        "        self.valid_accuracy_list.append(accuracy_valid)\n",
        "        self.visualizeTraining(0, confusionMatrixTrain,  cross = self.cross)\n",
        "        self.visualizeValAccuracy(0, confusionMatrixValid,  cross = self.cross)\n",
        "\n",
        "    def visualizeTraining(self, epoch, confusionMatrixTrain,  cross = 0):\n",
        "        # visualize the loss as the network trained\n",
        "        fig = plt.figure(figsize=(10, 8))\n",
        "        plt.plot(range(0, len(self.avg_train_losses)), self.avg_train_losses, label='Training Loss')\n",
        "        plt.plot(range(0, len(self.avg_valid_losses)), self.avg_valid_losses, label='Validation Loss')\n",
        "        minposs = self.avg_valid_losses.index(min(self.avg_valid_losses))\n",
        "        plt.axvline(minposs, linestyle='--', color='r', label='Early Stopping Checkpoint')\n",
        "\n",
        "\n",
        "        plt.xlabel('epochs')\n",
        "        plt.ylabel('loss')\n",
        "        plt.ylim(0, 0.5)  # consistent scale\n",
        "        plt.xlim(0, len(self.avg_train_losses))  # consistent scale\n",
        "        plt.grid(True)\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        fig.savefig(os.path.join(self.BASE_DIR , 'loss_plot_cross-{}_epoch-{}.png'.format(cross, epoch)), bbox_inches='tight')\n",
        "\n",
        "        fig = plt.figure(figsize=(10, 8))\n",
        "        confusionMatrixTrain = confusionMatrixTrain.numpy()\n",
        "        confusionMatrixTrain = confusionMatrixTrain / confusionMatrixTrain.astype(np.float).sum(axis=1, keepdims=True)\n",
        "        hmap = sns.heatmap(confusionMatrixTrain, annot=True,\n",
        "                           fmt='.2', cmap='Blues', annot_kws={\"size\": 6},xticklabels=self.lb.classes_, yticklabels=self.lb.classes_)\n",
        "        hmap.set_xticklabels(hmap.get_xmajorticklabels(), fontsize=6)\n",
        "        hmap.set_yticklabels(hmap.get_ymajorticklabels(), fontsize=6)\n",
        "        figure = hmap.get_figure()\n",
        "        figure.savefig(os.path.join(self.BASE_DIR ,'training_confusion_matrix_cross-{}_epoch-{}.png'.format(cross, epoch)), dpi=400)\n",
        "\n",
        "    def visualizeValAccuracy(self, epoch, confusionMatrix,  cross = 0):\n",
        "        # visualize the loss as the network trained\n",
        "        fig = plt.figure(figsize=(10, 8))\n",
        "        plt.plot(range(0, len(self.valid_accuracy_list)), self.valid_accuracy_list, label='Validation Accuracy')\n",
        "        plt.plot(range(0, len(self.train_accuracy_list)), self.train_accuracy_list, label='Training Accuracy')\n",
        "\n",
        "        # find position of lowest validation loss\n",
        "\n",
        "        plt.xlabel('epochs')\n",
        "        plt.ylabel('accuracy')\n",
        "        plt.grid(True)\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        fig.savefig(os.path.join(self.BASE_DIR , 'accuracy_plot_cross-{}_epoch-{}.png'.format(cross, epoch)), bbox_inches='tight')\n",
        "\n",
        "        fig = plt.figure(figsize=(10, 8))\n",
        "        confusionMatrix = confusionMatrix.numpy()\n",
        "        confusionMatrix = confusionMatrix / confusionMatrix.astype(np.float).sum(axis=1, keepdims=True)\n",
        "        hmap = sns.heatmap(confusionMatrix , annot=True,\n",
        "                    fmt='.2', cmap='Blues', annot_kws={\"size\": 6},xticklabels=self.lb.classes_, yticklabels=self.lb.classes_)\n",
        "        hmap.set_xticklabels(hmap.get_xmajorticklabels(), fontsize=6)\n",
        "        hmap.set_yticklabels(hmap.get_ymajorticklabels(), fontsize=6)\n",
        "        figure = hmap.get_figure()\n",
        "        figure.savefig(os.path.join(self.BASE_DIR ,'validation_confusion_matrix_cross-{}_epoch-{}.png'.format(cross, epoch)), dpi=400)\n",
        "\n",
        "\n",
        "    def visualizeLR(self, epoch, cross=0):\n",
        "        # visualize the loss as the network trained\n",
        "        fig = plt.figure(figsize=(10, 8))\n",
        "        plt.plot(range(0, len(self.LR)), self.LR, label='Learning rate')\n",
        "\n",
        "        # find position of lowest validation loss\n",
        "\n",
        "        if self.configuration.LR_DECAY_MODE == \"EPOCH\":\n",
        "            plt.xlabel('epochs')\n",
        "        else:\n",
        "            plt.xlabel('step')\n",
        "        plt.ylabel('learning rate')\n",
        "        plt.grid(True)\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        fig.savefig(os.path.join(self.BASE_DIR , 'lr_plot_cross-{}_epoch-{}.png'.format(cross, epoch)), bbox_inches='tight')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FUSYzZZJZlR"
      },
      "source": [
        "class CustomDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        print(\"inn dataset init\", tokenizer)\n",
        "        self.tokenizer = tokenizer\n",
        "        print(\"inn dataset init\", self.tokenizer)\n",
        "        self.data = dataframe\n",
        "        self.text = dataframe.text\n",
        "        self.targets = self.data.labelvec\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = str(self.text[index])\n",
        "        text = \" \".join(text.split()[0:self.max_len])\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            pad_to_max_length=True,\n",
        "            return_attention_mask=True,\n",
        "            truncation=True\n",
        "        )\n",
        "        ids = inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "\n",
        "        exclusionMask = torch.ones((1))\n",
        "\n",
        "        return torch.tensor(ids, dtype=torch.long), torch.tensor(mask, dtype=torch.long), torch.tensor(\n",
        "            self.targets[index], dtype=torch.float), exclusionMask"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooARIcAlJf8A"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    runMode = \"train\"\n",
        "    cross_Fold = False\n",
        "    BASE_DIR = \"/content/drive/My Drive/ICMPS/bert_mood_capsule_content\"\n",
        "    if(runMode==\"train\"):\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "              \n",
        "        if not os.path.exists(BASE_DIR):\n",
        "            os.mkdir(BASE_DIR)\n",
        "\n",
        "        originalData = pd.read_pickle(os.path.join(BASE_DIR, \"ml_balanced_data_augmented.pkl\"))\n",
        "\n",
        "        originalData = originalData.replace(np.nan, '', regex=True)\n",
        "\n",
        "        #originalData['lyrics'] = originalData['lyrics'].apply(lambda x: cleanSingleSentenceWithoutRemovingMeaning(x))\n",
        "\n",
        "        originalData = originalData[originalData['lyrics'] != \"\"]\n",
        "\n",
        "        originalData = originalData.reset_index(drop=True)\n",
        "\n",
        "        skfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=3)\n",
        "        val_acc_list = []\n",
        "        t = originalData.Mood\n",
        "        cross = 0\n",
        "        for train_index, test_index in skfold.split(np.zeros(len(t)), t):\n",
        "            train = originalData.iloc[train_index]\n",
        "            test = originalData.iloc[test_index]\n",
        "\n",
        "            train = train.reset_index(drop=True)\n",
        "            test = test.reset_index(drop=True)\n",
        "\n",
        "            bert_ensemble_model = BertEnsembleClassifier(BASE_DIR, mode=\"train\", cross=cross)\n",
        "            bert_ensemble_model.train(train, test, len(train.index), trainFromScratch=True)\n",
        "            print(\"After Training of the current fold - validation accuracy {}\".format(bert_ensemble_model.valid_accuracy_list))\n",
        "            val_acc_list.append(bert_ensemble_model.valid_accuracy_list)\n",
        "\n",
        "            if not cross_Fold:\n",
        "              break\n",
        "\n",
        "\n",
        "        print(\"final list {}\".format(val_acc_list))\n",
        "        accSum = []\n",
        "        for foldAcc in val_acc_list:\n",
        "            accSum.append(max(foldAcc))\n",
        "\n",
        "        print(\"max list {}\".format(accSum))\n",
        "        print(\"average accuracy {}\".format(np.average(accSum)))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    else:\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}