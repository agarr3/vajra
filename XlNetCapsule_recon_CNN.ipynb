{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "XlNetCapsule_recon_CNN.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c36be823c27e45fab284e7e401671044": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_78b01491beda4ccd82701e7db2dbc9d5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8098bb815bfd4506868ec163d40af146",
              "IPY_MODEL_8f4b5b9ba4264c84828f2054e9e4eda6"
            ]
          }
        },
        "78b01491beda4ccd82701e7db2dbc9d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8098bb815bfd4506868ec163d40af146": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8f3b63209b0b4962b5f07dc2c9ecfb87",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 798011,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 798011,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d6ae0ae49e7243d79e287ced06ad357a"
          }
        },
        "8f4b5b9ba4264c84828f2054e9e4eda6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_666aabb6d69a49a49600dab853d69c53",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 798k/798k [00:13&lt;00:00, 58.9kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a501284fb61b4875ac999203c5bc8280"
          }
        },
        "8f3b63209b0b4962b5f07dc2c9ecfb87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d6ae0ae49e7243d79e287ced06ad357a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "666aabb6d69a49a49600dab853d69c53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a501284fb61b4875ac999203c5bc8280": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f31d70441c4440cc9442ea0dd8d21bfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_80e212630c99403a943a262bc681f631",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e431d9af9a0a414292ae0c955128bc8a",
              "IPY_MODEL_9819c15ac096465d86f085e45339795f"
            ]
          }
        },
        "80e212630c99403a943a262bc681f631": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e431d9af9a0a414292ae0c955128bc8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_833208d132e04cb698d7aa80d1b96e9d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1382015,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1382015,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_288c9387e33f4355bf62d2fddb2f4c7f"
          }
        },
        "9819c15ac096465d86f085e45339795f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_961d36798d5e4f539a83281049d566fb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.38M/1.38M [00:04&lt;00:00, 296kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dbddcfc903244f6dbdba2780e826fb73"
          }
        },
        "833208d132e04cb698d7aa80d1b96e9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "288c9387e33f4355bf62d2fddb2f4c7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "961d36798d5e4f539a83281049d566fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dbddcfc903244f6dbdba2780e826fb73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agarr3/vajra/blob/master/XlNetCapsule_recon_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNVRhonwRLUm",
        "outputId": "c41c0cb5-ffb5-4a1c-c1e6-de601c836455"
      },
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "    process = psutil.Process(os.getpid())\n",
        "    print(\"Gen RAM Free: \" + humanize.naturalsize(psutil.virtual_memory().available), \" |     Proc size: \" + humanize.naturalsize(process.memory_info().rss))\n",
        "    print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total     {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()\n",
        "\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "  print('re-execute this cell.')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp37-none-any.whl size=7411 sha256=1a32a01df93558c11afe21fedd2f2872aa017dac5e200717c87b7e20e688b082\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.7/dist-packages (0.5.1)\n",
            "Gen RAM Free: 26.4 GB  |     Proc size: 118.5 MB\n",
            "GPU RAM Free: 16280MB | Used: 0MB | Util   0% | Total     16280MB\n",
            "Sun Jun 13 08:21:04 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNurW_GC_XdL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9067ea53-2d7d-4898-e98e-b8031aed2496"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install gensim\n",
        "#!pip install unidecode\n",
        "!pip install sentencepiece"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 15.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 48.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Collecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 60.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: sacremoses, huggingface-hub, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.6.1\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.0.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 14.8MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdWsZS1sHBZR"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "\n",
        "class EarlyStoppingAndCheckPointer:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "\n",
        "    def __init__(self, patience=7, verbose=False, delta=0, basedir='.', trace_func=print, epoch_level_save=False):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement.\n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "            path (str): Path for the checkpoint to be saved to.\n",
        "                            Default: 'checkpoint.pt'\n",
        "            trace_func (function): trace print function.\n",
        "                            Default: print\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.basedir = basedir\n",
        "        self.trace_func = trace_func\n",
        "        self.modelCheckPointer = ModelCheckPointer()\n",
        "        self.epoch_level_save = epoch_level_save\n",
        "\n",
        "    def __call__(self, val_loss, model, optimizer, epoch, scheduler):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.modelCheckPointer.save_checkpoint({'epoch': epoch + 1,\n",
        "                               'state_dict': model.state_dict(),\n",
        "                               'optim_dict' : optimizer.state_dict(),\n",
        "                                'sched_dict' : scheduler.state_dict()},\n",
        "                               is_best=True,\n",
        "                               checkpoint=self.basedir, save_epoch = self.epoch_level_save, epoch=epoch)\n",
        "            self.trace_func(\n",
        "                f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "            self.val_loss_min = val_loss\n",
        "\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            self.modelCheckPointer.save_checkpoint({'epoch': epoch + 1,\n",
        "                                                    'state_dict': model.state_dict(),\n",
        "                                                    'optim_dict': optimizer.state_dict(),\n",
        "                                                    'sched_dict' : scheduler.state_dict()},\n",
        "                                                   is_best=False,\n",
        "                                                   checkpoint=self.basedir, save_epoch = self.epoch_level_save, epoch=epoch)\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "            self.trace_func(\n",
        "                f'Validation loss did not decrease. The patience counter is ({self.counter} ).  Saving model as a resume checkpoint ...')\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.modelCheckPointer.save_checkpoint({'epoch': epoch + 1,\n",
        "                                                    'state_dict': model.state_dict(),\n",
        "                                                    'optim_dict': optimizer.state_dict(),\n",
        "                                                    'sched_dict' : scheduler.state_dict()},\n",
        "                                                   is_best=True,\n",
        "                                                   checkpoint=self.basedir, save_epoch = self.epoch_level_save, epoch=epoch)\n",
        "            self.counter = 0\n",
        "            self.trace_func(\n",
        "                f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "            self.val_loss_min = val_loss\n",
        "\n",
        "    # def save_checkpoint(self, val_loss, model):\n",
        "    #     '''Saves model when validation loss decrease.'''\n",
        "    #     if self.verbose:\n",
        "    #         self.trace_func(\n",
        "    #             f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "    #     torch.save(model.state_dict(), self.basedir)\n",
        "    #     self.val_loss_min = val_loss\n",
        "\n",
        "\n",
        "class ModelCheckPointer:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def save_checkpoint(self, state, is_best, checkpoint,  save_epoch = False, epoch=0):\n",
        "        \"\"\"Saves model and training parameters at checkpoint + 'last.pth.tar'. If is_best==True, also saves\n",
        "        checkpoint + 'best.pth.tar'\n",
        "        Args:\n",
        "            state: (dict) contains model's state_dict, may contain other keys such as epoch, optimizer state_dict\n",
        "            is_best: (bool) True if it is the best model seen till now\n",
        "            checkpoint: (string) folder where parameters are to be saved\n",
        "        \"\"\"\n",
        "        filepath = os.path.join(checkpoint, 'last.pth.tar')\n",
        "        if not os.path.exists(checkpoint):\n",
        "            print(\"Checkpoint Directory does not exist! Making directory {}\".format(checkpoint))\n",
        "            os.mkdirs(checkpoint)\n",
        "        else:\n",
        "            print(\"Checkpoint Directory exists! \")\n",
        "        torch.save(state, filepath)\n",
        "        if is_best:\n",
        "            shutil.copyfile(filepath, os.path.join(checkpoint, 'best.pth.tar'))\n",
        "        if save_epoch:\n",
        "            shutil.copyfile(filepath, os.path.join(checkpoint, 'epoch-{}.pth.tar'.format(epoch)))\n",
        "\n",
        "\n",
        "    def load_checkpoint(self, checkpoint, model, device, optimizer=None, scheduler=None):\n",
        "        \"\"\"Loads model parameters (state_dict) from file_path. If optimizer is provided, loads state_dict of\n",
        "        optimizer assuming it is present in checkpoint.\n",
        "        Args:\n",
        "            checkpoint: (string) filename which needs to be loaded\n",
        "            model: (torch.nn.Module) model for which the parameters are loaded\n",
        "            optimizer: (torch.optim) optional: resume optimizer from checkpoint\n",
        "        \"\"\"\n",
        "        filepath = os.path.join(checkpoint, 'last.pth.tar')\n",
        "        if not os.path.exists(filepath):\n",
        "            raise (\"File doesn't exist {}\".format(filepath))\n",
        "        checkpoint = torch.load(checkpoint)\n",
        "        model.load_state_dict(checkpoint['state_dict'], map_location=device)\n",
        "\n",
        "        if optimizer:\n",
        "            optimizer.load_state_dict(checkpoint['optim_dict'])\n",
        "        if scheduler:\n",
        "            scheduler.load_state_dict(checkpoint['sched_dict'])\n",
        "\n",
        "        return checkpoint['epoch']\n",
        "\n",
        "    def loadBestModel(self,checkpoint, model, device):\n",
        "        filepath = os.path.join(checkpoint, 'best.pth.tar')\n",
        "        if not os.path.exists(filepath):\n",
        "            raise (\"File doesn't exist {}\".format(filepath))\n",
        "        checkpoint = torch.load(filepath, map_location=device)\n",
        "        model.load_state_dict(checkpoint['state_dict'])\n",
        "\n",
        "class CustomLossUtils:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def getL1RegularizationLossTerm(self, model, params=None):\n",
        "        regularization_loss = 0\n",
        "        if params is None:\n",
        "            for param in model.parameters():\n",
        "                regularization_loss += torch.sum(torch.abs(param))\n",
        "        else:\n",
        "            for param in params:\n",
        "                regularization_loss += torch.sum(torch.abs(param))\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "ALPHA = 0.8\n",
        "GAMMA = 2\n",
        "\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True):\n",
        "        super(FocalLoss, self).__init__()\n",
        "\n",
        "    def forward(self, inputs, targets, alpha=ALPHA, gamma=GAMMA, smooth=1):\n",
        "        # comment out if your model contains a sigmoid or equivalent activation layer\n",
        "        inputs = F.sigmoid(inputs)\n",
        "\n",
        "        # flatten label and prediction tensors\n",
        "        inputs = inputs.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "\n",
        "        # first compute binary cross-entropy\n",
        "        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n",
        "        BCE_EXP = torch.exp(-BCE)\n",
        "        focal_loss = alpha * (1 - BCE_EXP) ** gamma * BCE\n",
        "\n",
        "        return focal_loss"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jno8QTjoMFny"
      },
      "source": [
        "\n",
        "from gensim.parsing.preprocessing import preprocess_documents, strip_tags, \\\n",
        "    strip_punctuation, strip_numeric, remove_stopwords, strip_short, stem_text\n",
        "\n",
        "from gensim.parsing.preprocessing import strip_multiple_whitespaces\n",
        "import unicodedata\n",
        "import re\n",
        "\n",
        "def remove_accented_chars(text):\n",
        "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "    return text\n",
        "\n",
        "def remove_special_characters(text, remove_digits=False):\n",
        "    pattern = r'[^a-zA-z0-9\\s]' if not remove_digits else r'[^a-zA-z\\s]'\n",
        "    text = re.sub(pattern, ' ', text)\n",
        "    return text\n",
        "\n",
        "def cleanSingleSentenceWithoutRemovingMeaning(x, minsize=3):\n",
        "    processedx = strip_tags(x)\n",
        "    #processedx = unidecode.unidecode(processedx)\n",
        "    processedx = remove_accented_chars(processedx)\n",
        "    processedx = remove_special_characters(processedx)\n",
        "    processedx = strip_multiple_whitespaces(processedx)\n",
        "    processedx = strip_numeric(processedx)\n",
        "    processedx = strip_short(processedx, minsize=minsize)\n",
        "    return processedx\n",
        "\n",
        "\n",
        "def transformSingle(x):\n",
        "    processedx = strip_tags(x)\n",
        "    processedx = strip_punctuation(processedx)\n",
        "    processedx = strip_multiple_whitespaces(processedx)\n",
        "    processedx = strip_numeric(processedx)\n",
        "    processedx = remove_stopwords(processedx)\n",
        "    processedx = strip_short(processedx)\n",
        "    #processedx = lemmatize_sentence(processedx)\n",
        "    processedx = remove_accented_chars(processedx)\n",
        "    processedx = remove_special_characters(processedx)\n",
        "    return processedx.lower()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oynKt5hEyU3"
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "\n",
        "\n",
        "def squash(inputs, axis=-1):\n",
        "    \"\"\"\n",
        "    The non-linear activation used in Capsule. It drives the length of a large vector to near 1 and small vector to 0\n",
        "    :param inputs: vectors to be squashed\n",
        "    :param axis: the axis to squash\n",
        "    :return: a Tensor with same size as inputs\n",
        "    \"\"\"\n",
        "    norm = torch.norm(inputs, p=2, dim=axis, keepdim=True)\n",
        "    scale = norm**2 / (1 + norm**2) / (norm + 1e-8)\n",
        "    return scale * inputs\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class FeatureExtractionConvolution(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Apply Conv2D with `out_channels` and then reshape to get capsules\n",
        "    :param in_channels: input channels\n",
        "    :param out_channels: output channels\n",
        "    :param dim_caps: dimension of capsule\n",
        "    :param kernel_size: kernel size\n",
        "    :return: output tensor, size=[batch, num_caps, dim_caps]\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, dim_caps, kernel_size, stride=1, padding=0):\n",
        "        super(FeatureExtractionConvolution, self).__init__()\n",
        "        self.dim_caps = dim_caps\n",
        "        self.conv2d = torch.nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "\n",
        "    def forward(self, x):\n",
        "        outputs = self.conv2d(x)\n",
        "        outputs = outputs.view(x.size(0), -1, self.dim_caps)\n",
        "        return squash(outputs)\n",
        "\n",
        "\n",
        "class DenseCapsule(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    The dense capsule layer. It is similar to Dense (FC) layer. Dense layer has `in_num` inputs, each is a scalar, the\n",
        "    output of the neuron from the former layer, and it has `out_num` output neurons. DenseCapsule just expands the\n",
        "    output of the neuron from scalar to vector. So its input size = [None, in_num_caps, in_dim_caps] and output size = \\\n",
        "    [None, out_num_caps, out_dim_caps]. For Dense Layer, in_dim_caps = out_dim_caps = 1.\n",
        "\n",
        "    :param in_num_caps: number of cpasules inputted to this layer\n",
        "    :param in_dim_caps: dimension of input capsules\n",
        "    :param out_num_caps: number of capsules outputted from this layer\n",
        "    :param out_dim_caps: dimension of output capsules\n",
        "    :param routings: number of iterations for the routing algorithm\n",
        "    \"\"\"\n",
        "    def __init__(self, in_num_caps, in_dim_caps, out_num_caps, out_dim_caps, routings=3):\n",
        "        super(DenseCapsule, self).__init__()\n",
        "        self.USE_CUDA = torch.cuda.is_available()\n",
        "        self.in_num_caps = in_num_caps\n",
        "        self.in_dim_caps = in_dim_caps\n",
        "        self.out_num_caps = out_num_caps\n",
        "        self.out_dim_caps = out_dim_caps\n",
        "        self.routings = routings\n",
        "        self.weight = torch.nn.Parameter(0.01 * torch.randn(out_num_caps, in_num_caps, out_dim_caps, in_dim_caps))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x.size=[batch, in_num_caps, in_dim_caps]\n",
        "        # expanded to    [batch, 1,            in_num_caps, in_dim_caps,  1]\n",
        "        # weight.size   =[       out_num_caps, in_num_caps, out_dim_caps, in_dim_caps]\n",
        "        # torch.matmul: [out_dim_caps, in_dim_caps] x [in_dim_caps, 1] -> [out_dim_caps, 1]\n",
        "        # => x_hat.size =[batch, out_num_caps, in_num_caps, out_dim_caps]\n",
        "        x_hat = torch.squeeze(torch.matmul(self.weight, x[:, None, :, :, None]), dim=-1)\n",
        "\n",
        "        # In forward pass, `x_hat_detached` = `x_hat`;\n",
        "        # In backward, no gradient can flow from `x_hat_detached` back to `x_hat`.\n",
        "        x_hat_detached = x_hat.detach()\n",
        "\n",
        "        # The prior for coupling coefficient, initialized as zeros.\n",
        "        # b.size = [batch, out_num_caps, in_num_caps]\n",
        "        if self.USE_CUDA:\n",
        "            b = Variable(torch.zeros(x.size(0), self.out_num_caps, self.in_num_caps)).cuda()\n",
        "        else:\n",
        "            b = Variable(torch.zeros(x.size(0), self.out_num_caps, self.in_num_caps))\n",
        "\n",
        "        assert self.routings > 0, 'The \\'routings\\' should be > 0.'\n",
        "        for i in range(self.routings):\n",
        "            # c.size = [batch, out_num_caps, in_num_caps]\n",
        "            c = F.softmax(b, dim=1)\n",
        "\n",
        "            # At last iteration, use `x_hat` to compute `outputs` in order to backpropagate gradient\n",
        "            if i == self.routings - 1:\n",
        "                # c.size expanded to [batch, out_num_caps, in_num_caps, 1           ]\n",
        "                # x_hat.size     =   [batch, out_num_caps, in_num_caps, out_dim_caps]\n",
        "                # => outputs.size=   [batch, out_num_caps, 1,           out_dim_caps]\n",
        "                outputs = squash(torch.sum(c[:, :, :, None] * x_hat, dim=-2, keepdim=True))\n",
        "                # outputs = squash(torch.matmul(c[:, :, None, :], x_hat))  # alternative way\n",
        "            else:  # Otherwise, use `x_hat_detached` to update `b`. No gradients flow on this path.\n",
        "                outputs = squash(torch.sum(c[:, :, :, None] * x_hat_detached, dim=-2, keepdim=True))\n",
        "                # outputs = squash(torch.matmul(c[:, :, None, :], x_hat_detached))  # alternative way\n",
        "\n",
        "                # outputs.size       =[batch, out_num_caps, 1,           out_dim_caps]\n",
        "                # x_hat_detached.size=[batch, out_num_caps, in_num_caps, out_dim_caps]\n",
        "                # => b.size          =[batch, out_num_caps, in_num_caps]\n",
        "                b = b + torch.sum(outputs * x_hat_detached, dim=-1)\n",
        "\n",
        "        return torch.squeeze(outputs, dim=-2)\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-tKt02t_UHj"
      },
      "source": [
        "import gc\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "\n",
        "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from transformers import LongformerTokenizer, LongformerConfig, get_linear_schedule_with_warmup, BertConfig, \\\n",
        "    BertTokenizer, BertModel, XLNetConfig, XLNetTokenizer, XLNetModel\n",
        "\n",
        "from transformers import BertForMaskedLM\n",
        "\n",
        "import joblib\n",
        "import torch\n",
        "from torch import cuda\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.utils.data.sampler import SequentialSampler\n",
        "from torch.hub import tqdm\n",
        "\n",
        "#from pytorchtools import EarlyStoppingAndCheckPointer, ModelCheckPointer\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from transformers.modeling_utils import SequenceSummary"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAtSRqfi--db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "c36be823c27e45fab284e7e401671044",
            "78b01491beda4ccd82701e7db2dbc9d5",
            "8098bb815bfd4506868ec163d40af146",
            "8f4b5b9ba4264c84828f2054e9e4eda6",
            "8f3b63209b0b4962b5f07dc2c9ecfb87",
            "d6ae0ae49e7243d79e287ced06ad357a",
            "666aabb6d69a49a49600dab853d69c53",
            "a501284fb61b4875ac999203c5bc8280",
            "f31d70441c4440cc9442ea0dd8d21bfd",
            "80e212630c99403a943a262bc681f631",
            "e431d9af9a0a414292ae0c955128bc8a",
            "9819c15ac096465d86f085e45339795f",
            "833208d132e04cb698d7aa80d1b96e9d",
            "288c9387e33f4355bf62d2fddb2f4c7f",
            "961d36798d5e4f539a83281049d566fb",
            "dbddcfc903244f6dbdba2780e826fb73"
          ]
        },
        "outputId": "c953b243-cab5-4e43-bc0a-581bc335c300"
      },
      "source": [
        "class BertEnsembleModelConfig:\n",
        "    defaultConfig = XLNetConfig()\n",
        "    model_name = 'xlnet-base-cased'\n",
        "    #model_name = \"xlnet-large-cased\"\n",
        "    labelEncoderFileName = 'labelEncoder_xlnet_mood.sav'\n",
        "    savedModelFileName = 'Bert_Ensemble_Model_v1.pt'\n",
        "    tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n",
        "    if model_name == 'xlnet-base-cased':\n",
        "        MAX_LEN = 1024\n",
        "        TRAIN_BATCH_SIZE = [1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
        "        LERANING_RATE_DECAY_MANUAL = [1, 0.9, 0.9*0.9*0.9, 0.9*0.9*0.9*0.9, 0.9*0.9*0.9*0.9*0.9, 0.9*0.9*0.9*0.9*0.9*0.9, 0.9*0.9*0.9*0.9*0.9*0.9*0.9, 0.9*0.9*0.9*0.9*0.9*0.9*0.9, 0.9*0.9*0.9*0.9*0.9*0.9*0.9*0.9*0.9]\n",
        "        ACCUMULATION_STEPS = 1\n",
        "        PATIENCE = 9\n",
        "        EPOCHS = 9\n",
        "        embedding_dim = 768\n",
        "    elif model_name == \"xlnet-large-cased\":\n",
        "        MAX_LEN = 1024\n",
        "        TRAIN_BATCH_SIZE = [1, 1, 1, 1, 1]\n",
        "        LERANING_RATE_DECAY_MANUAL = [1, 0.9, 0.9*0.9*0.9, 0.9*0.9*0.9*0.9, 0.9*0.9*0.9*0.9*0.9]\n",
        "        ACCUMULATION_STEPS = 1\n",
        "        PATIENCE = 3\n",
        "        EPOCHS = 5\n",
        "        embedding_dim = 1024\n",
        "    MAX_LEN_FILENAME = 20\n",
        "    VALID_BATCH_SIZE = 1\n",
        "    \n",
        "\n",
        "    LEARNING_RATE = 1e-05\n",
        "    \n",
        "    LEARNING_RATE_AUTO_DECAY_FLAG = False\n",
        "    LR_DECAY_MODE = \"EPOCH\"\n",
        "\n",
        "    WEIGHT_DECAY = 0.0\n",
        "    \n",
        "    WARM_UP_RATIO = 0.06\n",
        "    WARM_UP_STEPS = 0\n",
        "    max_grad_norm = None\n",
        "    #LOSS_FN = \"BCEWithLogitsLoss\"\n",
        "    #LOSS_FN = \"CrossEntropyLoss\"\n",
        "    LOSS_FN = \"MarginLoss\"\n",
        "    #BERT_MODEL_OP = \"last_hidden\"\n",
        "    BERT_MODEL_OP = \"CLS\"\n",
        "\n",
        "    VALID_FNAME_LEN_TH = 18\n",
        "    HELD_OUT_VALIDATION = True\n",
        "    CONDITIONAL_TRAINING = False\n",
        "\n",
        "    DETERMINISTIC = True\n",
        "    CAPS_PURE = True\n",
        "    RECONSTRUCTION_REGULARIZATION = True\n",
        "    \n",
        "    CLASS_LOSS_FN = \"BCEWithLogitsLoss\"\n",
        "    #CLASS_LOSS_FN = \"FocalLoss\"\n",
        "    USE_SEQUENCE_SUMMARY = True\n",
        "\n",
        "    if CAPS_PURE and not RECONSTRUCTION_REGULARIZATION:\n",
        "      LOSS_FN = \"MarginLoss\"\n",
        "    elif CAPS_PURE and RECONSTRUCTION_REGULARIZATION:\n",
        "      LOSS_FN = \"MarginMSELoss\"\n",
        "      USE_SEQUENCE_SUMMARY = True\n",
        "    else:\n",
        "      LOSS_FN = CLASS_LOSS_FN\n",
        "\n",
        "    \n",
        "    SQUASH_AFTER_TRANSFORMER = True\n",
        "    SOFTMAX_DENSE_LAYER = False\n",
        "\n",
        "    out_dim_caps = 64\n",
        "\n",
        "    \n",
        "    USE_CUDA = torch.cuda.is_available()\n",
        "\n",
        "    lam_recon = 0.0005 * embedding_dim\n",
        "    USE_CNN_LAYER = True\n",
        "    \n",
        "    \n",
        "  "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c36be823c27e45fab284e7e401671044",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=798011.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f31d70441c4440cc9442ea0dd8d21bfd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1382015.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPmN3ZaG_RI9"
      },
      "source": [
        "class BertEnsembletModel(torch.nn.Module):\n",
        "    '''\n",
        "    classdocs\n",
        "    '''\n",
        "\n",
        "    def __init__(self, num_classes, configuration=None):\n",
        "        super(BertEnsembletModel, self).__init__()\n",
        "        if configuration:\n",
        "            self.configuration = configuration\n",
        "        else:\n",
        "            self.configuration = BertEnsembleModelConfig()\n",
        "        self.bert_model_content = XLNetModel.from_pretrained(self.configuration.model_name, mem_len=1024)\n",
        "\n",
        "        xlNetDefConfig = XLNetConfig.from_pretrained(self.configuration.model_name)\n",
        "        self.sequence_summary = SequenceSummary(xlNetDefConfig)\n",
        "\n",
        "        self.cnnFeatureExtractor = FeatureExtractionConvolution(in_channels =1, out_channels=self.configuration.embedding_dim, dim_caps=self.configuration.embedding_dim, kernel_size = (3,self.configuration.embedding_dim))\n",
        "\n",
        "        if self.configuration.USE_SEQUENCE_SUMMARY:\n",
        "            in_num_caps = self.configuration.MAX_LEN + 1\n",
        "        else:\n",
        "            in_num_caps = self.configuration.MAX_LEN\n",
        "\n",
        "        if self.configuration.USE_CNN_LAYER:\n",
        "          in_num_caps = in_num_caps + (self.configuration.MAX_LEN - 3 + 1)\n",
        "\n",
        "        if(self.configuration.model_name == \"xlnet-large-cased\"):\n",
        "            \n",
        "            self.digitcaps = DenseCapsule(in_num_caps=in_num_caps,\n",
        "                                          in_dim_caps=self.configuration.embedding_dim,\n",
        "                                          out_num_caps=num_classes, out_dim_caps=self.configuration.out_dim_caps,\n",
        "                                          routings=3)\n",
        "            \n",
        "        elif (self.configuration.model_name == \"xlnet-base-cased\"):\n",
        "            \n",
        "            self.digitcaps = DenseCapsule(in_num_caps=in_num_caps,\n",
        "                                          in_dim_caps=self.configuration.embedding_dim,\n",
        "                                          out_num_caps=num_classes, out_dim_caps=self.configuration.out_dim_caps,\n",
        "                                          routings=3)\n",
        "\n",
        "        self.dense = torch.nn.Linear(num_classes * self.configuration.out_dim_caps, num_classes * self.configuration.out_dim_caps)\n",
        "        self.softmax = torch.nn.Softmax()\n",
        "        self.dropout = torch.nn.Dropout(0.3)\n",
        "        self.classifier = torch.nn.Linear(num_classes * self.configuration.out_dim_caps, num_classes)\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(self.configuration.out_dim_caps * num_classes, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(512, 768),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(768, self.configuration.embedding_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(\n",
        "            self,\n",
        "            input_ids=None,\n",
        "            attention_mask=None,\n",
        "            token_type_ids=None,\n",
        "            position_ids=None,\n",
        "            head_mask=None,\n",
        "            inputs_embeds=None,\n",
        "            class_label=None,\n",
        "            exclusion_mask= None\n",
        "    ):\n",
        "\n",
        "        content_output = self.bert_model_content(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        if exclusion_mask is not None and self.configuration.CONDITIONAL_TRAINING:\n",
        "            content_output = content_output[0] * exclusion_mask[0].unsqueeze(dim=-1)\n",
        "        else:\n",
        "            content_output = content_output[0]\n",
        "\n",
        "        if self.configuration.USE_CNN_LAYER:\n",
        "          feature_cnn = self.cnnFeatureExtractor(content_output.unsqueeze(dim=1))\n",
        "        \n",
        "        if self.configuration.USE_SEQUENCE_SUMMARY:\n",
        "            output_summary = self.sequence_summary(content_output)\n",
        "            content_output = torch.cat([content_output, output_summary.unsqueeze(dim=1)], dim=1)\n",
        "        \n",
        "        if self.configuration.USE_CNN_LAYER:\n",
        "          content_output = torch.cat([content_output, feature_cnn], dim=1)\n",
        "\n",
        "\n",
        "        if self.configuration.USE_CNN_LAYER:\n",
        "          feature_cnn = self.cnnFeatureExtractor(content_output.unsqueeze(dim=1))\n",
        "\n",
        "\n",
        "        if self.configuration.SQUASH_AFTER_TRANSFORMER:\n",
        "            op_bert_ensemble = squash(content_output)\n",
        "        else:\n",
        "            op_bert_ensemble = content_output\n",
        "        \n",
        "        \n",
        "        classvecs = self.digitcaps(op_bert_ensemble)\n",
        "\n",
        "        if self.configuration.CAPS_PURE:\n",
        "            outputs = classvecs.norm(dim=-1)\n",
        "            if self.configuration.RECONSTRUCTION_REGULARIZATION:\n",
        "              index = outputs.max(dim=1)[1]\n",
        "              if self.configuration.USE_CUDA:\n",
        "                y = Variable(torch.zeros(outputs.size()).scatter_(1, index.view(-1, 1).cpu().data, 1.).cuda())\n",
        "              else:\n",
        "                y = Variable(torch.zeros(outputs.size()).scatter_(1, index.view(-1, 1).cpu().data, 1.))\n",
        "\n",
        "\n",
        "              # print(\"outputs.shape\", outputs.shape)\n",
        "              # print(\"y.shape\", y.shape)\n",
        "              reconstruction = self.decoder((classvecs * y[:, :, None]).view(classvecs.size(0), -1))\n",
        "        else:\n",
        "            classvecs_fl = classvecs.view(input_ids.size(0), -1)\n",
        "            if self.configuration.SOFTMAX_DENSE_LAYER:\n",
        "                x = self.softmax(self.dense(classvecs_fl))\n",
        "            else:\n",
        "                x = self.dense(classvecs_fl)\n",
        "            x = self.dropout(x)\n",
        "            outputs = self.classifier(x)\n",
        "\n",
        "        \n",
        "\n",
        "        if not self.configuration.RECONSTRUCTION_REGULARIZATION:\n",
        "          return outputs, None, None\n",
        "        else:\n",
        "          return outputs, reconstruction, output_summary"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpX1OfB6JTmA"
      },
      "source": [
        "class BertEnsembleClassifier(object):\n",
        "    '''\n",
        "    classdocs\n",
        "    '''\n",
        "\n",
        "    def __init__(self, base_dir, modelOverRideForEval = None,  configuration=None, mode=\"eval\", cross=0):\n",
        "        '''\n",
        "        Constructor\n",
        "        '''\n",
        "        if configuration:\n",
        "            self.configuration = configuration\n",
        "        else:\n",
        "            self.configuration = BertEnsembleModelConfig()\n",
        "        self.BASE_DIR = base_dir\n",
        "        self.labelEncoderPath = os.path.join(self.BASE_DIR, self.configuration.labelEncoderFileName)\n",
        "        self.modelPath = os.path.join(self.BASE_DIR, self.configuration.savedModelFileName)\n",
        "        self.device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "        self.cross = cross\n",
        "\n",
        "        if self.configuration.DETERMINISTIC:\n",
        "            self.seed_everything()\n",
        "\n",
        "        self.tokenizer = self.configuration.tokenizer\n",
        "        if mode == \"eval\":\n",
        "            self.lb = joblib.load(self.labelEncoderPath)\n",
        "            self.model = BertEnsembletModel(len(self.lb.classes_), self.configuration)\n",
        "            if modelOverRideForEval:\n",
        "                self.model.load_state_dict(torch.load(modelOverRideForEval, map_location=self.device))\n",
        "                self.model.eval()\n",
        "            else:\n",
        "                modelCheckpointer = ModelCheckPointer()\n",
        "                modelCheckpointer.loadBestModel(self.BASE_DIR, self.model, self.device)\n",
        "                self.model.eval()\n",
        "        elif mode == \"train\":\n",
        "            self.avg_train_losses = []\n",
        "            self.avg_valid_losses = []\n",
        "            self.train_accuracy_list = []\n",
        "            self.valid_accuracy_list = []\n",
        "            self.LR = []\n",
        "            self.DEBUG_INCORRECT = {}\n",
        "\n",
        "\n",
        "        else:\n",
        "            raise Exception(\"illegal mode\")\n",
        "\n",
        "    def predict(self, content, processed=False):\n",
        "\n",
        "        self.model.eval()\n",
        "        if not processed:\n",
        "            content = cleanSingleSentenceWithoutRemovingMeaning(content)\n",
        "\n",
        "        content = \" \".join(content.split(\" \")[0:self.configuration.MAX_LEN])\n",
        "\n",
        "        with torch.no_grad():\n",
        "            inputs = self.tokenizer.encode_plus(\n",
        "                content,\n",
        "                None,\n",
        "                add_special_tokens=True,\n",
        "                max_length=self.configuration.MAX_LEN,\n",
        "                pad_to_max_length=True,\n",
        "                return_attention_mask=True,\n",
        "                # return_tensors='pt',\n",
        "                truncation=True\n",
        "            )\n",
        "            ids = inputs['input_ids']\n",
        "            mask = inputs['attention_mask']\n",
        "\n",
        "            ids = [ids]\n",
        "            mask = [mask]\n",
        "\n",
        "            contentIds = torch.tensor(ids, dtype=torch.long)\n",
        "            contentMask = torch.tensor(mask, dtype=torch.long)\n",
        "            contenteExclusionMask = torch.ones((1))\n",
        "\n",
        "            inputs = {\n",
        "                \"input_ids\": contentIds,\n",
        "                \"attention_mask\": contentMask,\n",
        "                \"exclusion_mask\": contenteExclusionMask\n",
        "            }\n",
        "\n",
        "            outputs, reconstruction, output_summary = self.model(**inputs)\n",
        "            prediction = torch.sigmoid(outputs)\n",
        "\n",
        "        return self.lb.inverse_transform(prediction.detach().numpy())\n",
        "\n",
        "    def seed_everything(self, seed=1234):\n",
        "        random.seed(seed)\n",
        "        torch.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        np.random.seed(seed)\n",
        "        os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "\n",
        "    def loss_fn(self, outputs, targets, reconstruction=None, recon_target=None):\n",
        "        if self.configuration.LOSS_FN == \"CrossEntropyLoss\":\n",
        "          torch.nn.CrossEntropyLoss()(outputs, targets)\n",
        "        elif self.configuration.LOSS_FN == \"BCEWithLogitsLoss\":\n",
        "          return torch.nn.BCEWithLogitsLoss()(outputs, targets)\n",
        "        elif self.configuration.LOSS_FN == \"MarginLoss\":\n",
        "          return self.caps_loss(targets, outputs)\n",
        "        elif self.configuration.LOSS_FN == \"MarginMSELoss\" and reconstruction is not None:\n",
        "          return self.caps_loss(targets, outputs) + self.configuration.lam_recon * torch.nn.MSELoss()(reconstruction, recon_target)\n",
        "\n",
        "        elif self.configuration.LOSS_FN == \"FocalLoss\":\n",
        "          return FocalLoss()(outputs, targets)\n",
        "\n",
        "    def caps_loss(self, y_true, y_pred):\n",
        "        \"\"\"\n",
        "        Capsule loss = Margin loss\n",
        "        :param y_true: true labels, one-hot coding, size=[batch, classes]\n",
        "        :param y_pred: predicted labels by CapsNet, size=[batch, classes]\n",
        "        :return: Variable contains a scalar loss value.\n",
        "        \"\"\"\n",
        "        L = y_true * torch.clamp(0.9 - y_pred, min=0.) ** 2 + \\\n",
        "            0.5 * (1 - y_true) * torch.clamp(y_pred - 0.1, min=0.) ** 2\n",
        "        L_margin = L.sum(dim=1).mean()\n",
        "\n",
        "        return L_margin\n",
        "\n",
        "    def run_evaluation(self, model, validation_data_loader_content):\n",
        "        model.eval()\n",
        "        valid_losses = []\n",
        "        accuracyBoolList = []\n",
        "        confusionMatrix = torch.zeros(len(self.lb.classes_), len(self.lb.classes_))\n",
        "        inncorrectPreds = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "          for step, batch in tqdm(enumerate(validation_data_loader_content), desc=\"running evaluation\"):\n",
        "              contentBatch = batch\n",
        "              batch_1 = tuple(t.to(self.device) for t in contentBatch)\n",
        "\n",
        "              targets = batch_1[2]\n",
        "              inputs = {\n",
        "                  \"input_ids\": batch_1[0],\n",
        "                  \"attention_mask\": batch_1[1],\n",
        "                  \"exclusion_mask\": batch_1[3]\n",
        "              }\n",
        "              outputs, reconstruction, output_summary = model(**inputs)\n",
        "              loss = self.loss_fn(outputs, targets, reconstruction=reconstruction, recon_target=output_summary)\n",
        "              valid_losses.append(loss.item())\n",
        "              _, predicted = torch.max(outputs, 1)\n",
        "              _, trueClass = torch.max(targets, 1)\n",
        "              for trueClassLabel, predictedClassLabel in zip(trueClass, predicted):\n",
        "                  confusionMatrix[trueClassLabel, predictedClassLabel] = confusionMatrix[trueClassLabel, predictedClassLabel] +1\n",
        "              booleans = (predicted == trueClass)\n",
        "              accuracyBoolList.extend([boolean.item() for boolean in booleans])\n",
        "              \n",
        "              # print(\"predicted\")\n",
        "              # print(predicted)\n",
        "              # print(trueClass)\n",
        "\n",
        "              \n",
        "              incorrectPredictionIndices = [i for i, x in enumerate(booleans) if not x]\n",
        "              for index in incorrectPredictionIndices:\n",
        "                inncorrectPreds.append(batch_1[0][index].detach().cpu().numpy())\n",
        "                  \n",
        "                  \n",
        "\n",
        "              del outputs, inputs, batch_1\n",
        "              gc.collect()\n",
        "        return valid_losses, accuracyBoolList, confusionMatrix, inncorrectPreds\n",
        "\n",
        "    def run_training(self, epoch, model, training_data_loader_content, optimizer, scheduler):\n",
        "\n",
        "        model.train()\n",
        "        model.zero_grad()\n",
        "        train_losses = []\n",
        "        accuracyBoolList = []\n",
        "        confusionMatrix = torch.zeros(len(self.lb.classes_), len(self.lb.classes_))\n",
        "\n",
        "        for step, batch in tqdm(enumerate(training_data_loader_content), desc=\"running training for epoch {}\".format(epoch)):\n",
        "            contentBatch = batch\n",
        "\n",
        "            batch_1 = tuple(t.to(self.device) for t in contentBatch)\n",
        "\n",
        "            targets = batch_1[2]\n",
        "            inputs = {\n",
        "                \"input_ids\": batch_1[0],\n",
        "                \"attention_mask\": batch_1[1],\n",
        "                \"exclusion_mask\": batch_1[3]\n",
        "            }\n",
        "            outputs, reconstruction, output_summary = model(**inputs)\n",
        "            loss = self.loss_fn(outputs, targets, reconstruction=reconstruction, recon_target=output_summary)\n",
        "            train_losses.append(loss.item())\n",
        "            if self.configuration.ACCUMULATION_STEPS != 1:\n",
        "                loss = loss / self.configuration.ACCUMULATION_STEPS\n",
        "            loss.backward()\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            _, trueClass = torch.max(targets, 1)\n",
        "            for trueClassLabel, predictedClassLabel in zip(trueClass, predicted):\n",
        "                confusionMatrix[trueClassLabel, predictedClassLabel] = confusionMatrix[\n",
        "                                                                           trueClassLabel, predictedClassLabel] + 1\n",
        "            booleans = (predicted == trueClass)\n",
        "            accuracyBoolList.extend([boolean.item() for boolean in booleans])\n",
        "\n",
        "            if (step + 1) % self.configuration.ACCUMULATION_STEPS == 0:\n",
        "                if self.configuration.max_grad_norm is not None:\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), self.configuration.max_grad_norm)\n",
        "                optimizer.step()  # Now we can do an optimizer step\n",
        "                if self.configuration.LR_DECAY_MODE == \"BATCH\" and self.configuration.LEARNING_RATE_AUTO_DECAY_FLAG:\n",
        "                    print(\"Learning rate decay at batch level, reducing LR\")\n",
        "                    scheduler.step()\n",
        "                    self.LR.append(scheduler.get_lr())\n",
        "                #optimizer.zero_grad()\n",
        "                model.zero_grad()\n",
        "                print('Epoch: {}, step: {},  Loss:  {}'.format(epoch, step, loss.item()))\n",
        "\n",
        "\n",
        "            del outputs, inputs, batch_1\n",
        "            gc.collect()\n",
        "        return train_losses, accuracyBoolList, confusionMatrix\n",
        "\n",
        "    def train(self, training_data, testing_data, trainDataSize, trainFromScratch=True):\n",
        "\n",
        "        self.lb = LabelBinarizer()\n",
        "        training_data['labelvec'] = self.lb.fit_transform(training_data['Mood']).tolist()\n",
        "\n",
        "        training_data_content = training_data[['lyrics', 'labelvec']]\n",
        "        training_data_content = training_data_content.rename(columns={\"lyrics\": \"text\"})\n",
        "        joblib.dump(self.lb, self.labelEncoderPath)\n",
        "\n",
        "        testing_data['labelvec'] = self.lb.transform(testing_data['Mood']).tolist()\n",
        "\n",
        "        testingDataContent = testing_data[['lyrics', 'labelvec']]\n",
        "        testingDataContent = testingDataContent.rename(columns={\"lyrics\": \"text\"})\n",
        "\n",
        "        print(\"creatinng dataset. The tokenizer is \", self.tokenizer)\n",
        "        content_training_set = CustomDataset(training_data_content, self.tokenizer, self.configuration.MAX_LEN)\n",
        "        content_testing_set = CustomDataset(testingDataContent, self.tokenizer, self.configuration.MAX_LEN)\n",
        "\n",
        "\n",
        "        content_training_loader = DataLoader(content_training_set,\n",
        "                                             batch_size=self.configuration.TRAIN_BATCH_SIZE[0],\n",
        "                                             sampler=SequentialSampler(content_training_set), drop_last=False)\n",
        "\n",
        "\n",
        "        content_testing_loader = DataLoader(content_testing_set,\n",
        "                                               batch_size=self.configuration.VALID_BATCH_SIZE,\n",
        "                                               sampler=SequentialSampler(content_testing_set), drop_last=False)\n",
        "\n",
        "\n",
        "        model = BertEnsembletModel(len(self.lb.classes_))\n",
        "\n",
        "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "        if self.configuration.WEIGHT_DECAY == 0.0:\n",
        "            print(\"weight decay parameter is 0 so, using no weight decay anywhere\")\n",
        "            optimizer_grouped_parameters = [{\n",
        "                \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "            }]\n",
        "        else:\n",
        "            print(\"weight decay parameter is {} so, using this weight decay anywhere\".format(self.configuration.WEIGHT_DECAY))\n",
        "            optimizer_grouped_parameters = [\n",
        "                {\n",
        "                    \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "                    \"weight_decay\": self.configuration.WEIGHT_DECAY,\n",
        "                },\n",
        "                {\n",
        "                    \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "                    \"weight_decay\": 0.0,\n",
        "                },\n",
        "            ]\n",
        "\n",
        "        if self.configuration.LR_DECAY_MODE == \"BATCH\":\n",
        "            t_total = len(content_training_loader) // self.configuration.ACCUMULATION_STEPS * self.configuration.EPOCHS\n",
        "            print(\"Learning rate decay at batch level, t_total is {}\".format(t_total))\n",
        "        elif self.configuration.LR_DECAY_MODE == \"EPOCH\":\n",
        "            t_total = self.configuration.EPOCHS\n",
        "            print(\"Learning rate decay at epoch level, t_total is {}\".format(t_total))\n",
        "\n",
        "        if self.configuration.WARM_UP_STEPS == None:\n",
        "            warmup_steps = math.ceil(t_total * self.configuration.WARM_UP_RATIO)\n",
        "        else:\n",
        "            warmup_steps = self.configuration.WARM_UP_STEPS\n",
        "        optimizer = torch.optim.AdamW(params=optimizer_grouped_parameters, lr=self.configuration.LEARNING_RATE)\n",
        "        scheduler = get_linear_schedule_with_warmup(\n",
        "            optimizer, num_warmup_steps=warmup_steps, num_training_steps=t_total\n",
        "        )\n",
        "\n",
        "        savedEpoch = 0\n",
        "        if not trainFromScratch:\n",
        "            # PATH = previousSavedModel\n",
        "            modelCheckpointer = ModelCheckPointer()\n",
        "            savedEpoch = modelCheckpointer.load_checkpoint(self.BASE_DIR, model, self.device, optimizer, scheduler)\n",
        "            # model.load_state_dict(torch.load(PATH, map_location=self.device))\n",
        "        model.to(self.device)\n",
        "\n",
        "        early_stopping = EarlyStoppingAndCheckPointer(patience=self.configuration.PATIENCE, verbose=True, basedir=self.BASE_DIR, epoch_level_save=False)\n",
        "\n",
        "        #self.initialLog(model,content_training_loader, content_testing_loader)\n",
        "        for epoch in range(savedEpoch, self.configuration.EPOCHS):\n",
        "            print(\"starting training. The LR is {}\".format(scheduler.get_lr()))\n",
        "\n",
        "            trainBatchSizeForEpoch = self.configuration.TRAIN_BATCH_SIZE[epoch]\n",
        "            if trainBatchSizeForEpoch < 1:\n",
        "                trainBatchSizeForEpoch = 1\n",
        "            content_training_loader = DataLoader(content_training_set,\n",
        "                                                 batch_size=trainBatchSizeForEpoch,\n",
        "                                                 sampler=SequentialSampler(content_training_set), drop_last=False)\n",
        "\n",
        "\n",
        "            if not self.configuration.LEARNING_RATE_AUTO_DECAY_FLAG:\n",
        "                lrForEpoch = self.configuration.LEARNING_RATE * self.configuration.LERANING_RATE_DECAY_MANUAL[epoch]\n",
        "                for param_group in optimizer.param_groups:\n",
        "                    param_group['lr'] = lrForEpoch\n",
        "                    print(\"setting LR manually to {}\".format(lrForEpoch))\n",
        "\n",
        "            train_losses, accuracyBoolListTrain, confusionMatrixTrain = self.run_training(epoch, model, content_training_loader, optimizer, scheduler)\n",
        "            if self.configuration.LR_DECAY_MODE == \"EPOCH\" and self.configuration.LEARNING_RATE_AUTO_DECAY_FLAG:\n",
        "                scheduler.step()\n",
        "                print(\"Learning rate decay at epoch level, reducing LR to {}\".format(scheduler.get_lr()))\n",
        "                self.LR.append(scheduler.get_lr())\n",
        "\n",
        "            valid_losses, accuracyBoolListValid, confusionMatrixValid, inncorrectPreds = self.run_evaluation(model, content_testing_loader)\n",
        "\n",
        "            train_loss = np.average(train_losses)\n",
        "            valid_loss = np.average(valid_losses)\n",
        "            accuracy_train = sum(accuracyBoolListTrain)/len(accuracyBoolListTrain) * 100\n",
        "            accuracy_valid = sum(accuracyBoolListValid) / len(accuracyBoolListValid) * 100\n",
        "\n",
        "            self.avg_train_losses.append(train_loss)\n",
        "            self.avg_valid_losses.append(valid_loss)\n",
        "            self.train_accuracy_list.append(accuracy_train)\n",
        "            self.valid_accuracy_list.append(accuracy_valid)\n",
        "\n",
        "            print('Epoch: {},  Total Train Loss:  {}'.format(epoch+1, train_loss))\n",
        "            print('Epoch: {},  Total Validation Loss:  {}'.format(epoch+1, valid_loss))\n",
        "            print('Epoch: {},  Total training accuracy:  {}'.format(epoch+1, accuracy_train))\n",
        "            print('Epoch: {},  Total Validation accuracy:  {}'.format(epoch+1, accuracy_valid))\n",
        "\n",
        "            early_stopping(valid_loss, model, optimizer, epoch, scheduler)\n",
        "\n",
        "\n",
        "            self.visualizeTraining(epoch+1, confusionMatrixTrain, cross = self.cross)\n",
        "            self.visualizeValAccuracy(epoch+1, confusionMatrixValid, cross = self.cross)\n",
        "            self.visualizeLR(epoch + 1,  cross = self.cross)\n",
        "            if early_stopping.early_stop:\n",
        "                print(\"Early stopping\")\n",
        "                self.model = model\n",
        "                break\n",
        "\n",
        "    def initialLog(self, model,\n",
        "                   content_training_loader,\n",
        "                   content_testing_loader):\n",
        "        train_losses, accuracyBoolListTrain, confusionMatrixTrain = self.run_evaluation(model,content_training_loader)\n",
        "        valid_losses, accuracyBoolListValid, confusionMatrixValid = self.run_evaluation(model,content_testing_loader)\n",
        "\n",
        "        train_loss = np.average(train_losses)\n",
        "        valid_loss = np.average(valid_losses)\n",
        "        accuracy_train = sum(accuracyBoolListTrain) / len(accuracyBoolListTrain) * 100\n",
        "        accuracy_valid = sum(accuracyBoolListValid) / len(accuracyBoolListValid) * 100\n",
        "\n",
        "        self.avg_train_losses.append(train_loss)\n",
        "        self.avg_valid_losses.append(valid_loss)\n",
        "        self.train_accuracy_list.append(accuracy_train)\n",
        "        self.valid_accuracy_list.append(accuracy_valid)\n",
        "        self.visualizeTraining(0, confusionMatrixTrain,  cross = self.cross)\n",
        "        self.visualizeValAccuracy(0, confusionMatrixValid,  cross = self.cross)\n",
        "\n",
        "    def visualizeTraining(self, epoch, confusionMatrixTrain,  cross = 0):\n",
        "        # visualize the loss as the network trained\n",
        "        fig = plt.figure(figsize=(10, 8))\n",
        "        plt.plot(range(0, len(self.avg_train_losses)), self.avg_train_losses, label='Training Loss')\n",
        "        plt.plot(range(0, len(self.avg_valid_losses)), self.avg_valid_losses, label='Validation Loss')\n",
        "        minposs = self.avg_valid_losses.index(min(self.avg_valid_losses))\n",
        "        plt.axvline(minposs, linestyle='--', color='r', label='Early Stopping Checkpoint')\n",
        "\n",
        "\n",
        "        plt.xlabel('epochs')\n",
        "        plt.ylabel('loss')\n",
        "        plt.ylim(0, 0.5)  # consistent scale\n",
        "        plt.xlim(0, len(self.avg_train_losses))  # consistent scale\n",
        "        plt.grid(True)\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        fig.savefig(os.path.join(self.BASE_DIR , 'loss_plot_cross-{}_epoch-{}.png'.format(cross, epoch)), bbox_inches='tight')\n",
        "\n",
        "        fig = plt.figure(figsize=(10, 8))\n",
        "        confusionMatrixTrain = confusionMatrixTrain.numpy()\n",
        "        confusionMatrixTrain = confusionMatrixTrain / confusionMatrixTrain.astype(np.float).sum(axis=1, keepdims=True)\n",
        "        hmap = sns.heatmap(confusionMatrixTrain, annot=True,\n",
        "                           fmt='.2', cmap='Blues', annot_kws={\"size\": 6},xticklabels=self.lb.classes_, yticklabels=self.lb.classes_)\n",
        "        hmap.set_xticklabels(hmap.get_xmajorticklabels(), fontsize=6)\n",
        "        hmap.set_yticklabels(hmap.get_ymajorticklabels(), fontsize=6)\n",
        "        figure = hmap.get_figure()\n",
        "        figure.savefig(os.path.join(self.BASE_DIR ,'training_confusion_matrix_cross-{}_epoch-{}.png'.format(cross, epoch)), dpi=400)\n",
        "\n",
        "    def visualizeValAccuracy(self, epoch, confusionMatrix,  cross = 0):\n",
        "        # visualize the loss as the network trained\n",
        "        fig = plt.figure(figsize=(10, 8))\n",
        "        plt.plot(range(0, len(self.valid_accuracy_list)), self.valid_accuracy_list, label='Validation Accuracy')\n",
        "        plt.plot(range(0, len(self.train_accuracy_list)), self.train_accuracy_list, label='Training Accuracy')\n",
        "\n",
        "        # find position of lowest validation loss\n",
        "\n",
        "        plt.xlabel('epochs')\n",
        "        plt.ylabel('accuracy')\n",
        "        plt.grid(True)\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        fig.savefig(os.path.join(self.BASE_DIR , 'accuracy_plot_cross-{}_epoch-{}.png'.format(cross, epoch)), bbox_inches='tight')\n",
        "\n",
        "        fig = plt.figure(figsize=(10, 8))\n",
        "        confusionMatrix = confusionMatrix.numpy()\n",
        "        confusionMatrix = confusionMatrix / confusionMatrix.astype(np.float).sum(axis=1, keepdims=True)\n",
        "        hmap = sns.heatmap(confusionMatrix , annot=True,\n",
        "                    fmt='.2', cmap='Blues', annot_kws={\"size\": 6},xticklabels=self.lb.classes_, yticklabels=self.lb.classes_)\n",
        "        hmap.set_xticklabels(hmap.get_xmajorticklabels(), fontsize=6)\n",
        "        hmap.set_yticklabels(hmap.get_ymajorticklabels(), fontsize=6)\n",
        "        figure = hmap.get_figure()\n",
        "        figure.savefig(os.path.join(self.BASE_DIR ,'validation_confusion_matrix_cross-{}_epoch-{}.png'.format(cross, epoch)), dpi=400)\n",
        "\n",
        "\n",
        "    def visualizeLR(self, epoch, cross=0):\n",
        "        # visualize the loss as the network trained\n",
        "        fig = plt.figure(figsize=(10, 8))\n",
        "        plt.plot(range(0, len(self.LR)), self.LR, label='Learning rate')\n",
        "\n",
        "        # find position of lowest validation loss\n",
        "\n",
        "        if self.configuration.LR_DECAY_MODE == \"EPOCH\":\n",
        "            plt.xlabel('epochs')\n",
        "        else:\n",
        "            plt.xlabel('step')\n",
        "        plt.ylabel('learning rate')\n",
        "        plt.grid(True)\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        fig.savefig(os.path.join(self.BASE_DIR , 'lr_plot_cross-{}_epoch-{}.png'.format(cross, epoch)), bbox_inches='tight')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FUSYzZZJZlR"
      },
      "source": [
        "class CustomDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        print(\"inn dataset init\", tokenizer)\n",
        "        self.tokenizer = tokenizer\n",
        "        print(\"inn dataset init\", self.tokenizer)\n",
        "        self.data = dataframe\n",
        "        self.text = dataframe.text\n",
        "        self.targets = self.data.labelvec\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = str(self.text[index])\n",
        "        text = \" \".join(text.split()[0:self.max_len])\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            pad_to_max_length=True,\n",
        "            return_attention_mask=True,\n",
        "            truncation=True\n",
        "        )\n",
        "        ids = inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "\n",
        "        exclusionMask = torch.ones((1))\n",
        "\n",
        "        return torch.tensor(ids, dtype=torch.long), torch.tensor(mask, dtype=torch.long), torch.tensor(\n",
        "            self.targets[index], dtype=torch.float), exclusionMask"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooARIcAlJf8A"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    runMode = \"train\"\n",
        "    cross_Fold = False\n",
        "    BASE_DIR = \"/content/drive/My Drive/ICMPS/bert_mood_capsule_content_test2\"\n",
        "    if(runMode==\"train\"):\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "              \n",
        "        if not os.path.exists(BASE_DIR):\n",
        "            os.mkdir(BASE_DIR)\n",
        "\n",
        "        #originalData = pd.read_pickle(os.path.join(BASE_DIR, \"ml_balanced_data_augmented.pkl\"))\n",
        "\n",
        "        originalData = pd.read_pickle(os.path.join(BASE_DIR, \"Moody_lyrics_additional_data.pkl\"))\n",
        "        originalData = originalData.rename(columns={'Lyrics':'lyrics'})\n",
        "\n",
        "        originalData = originalData.replace(np.nan, '', regex=True)\n",
        "\n",
        "        originalData['lyrics'] = originalData['lyrics'].apply(lambda x: cleanSingleSentenceWithoutRemovingMeaning(x))\n",
        "\n",
        "        #originalData['lyrics'] = originalData['lyrics'].apply(lambda x: transformSingle(x))\n",
        "\n",
        "        originalData = originalData[originalData['lyrics'] != \"\"]\n",
        "\n",
        "        originalData = originalData.reset_index(drop=True)\n",
        "\n",
        "        skfold = StratifiedKFold(n_splits=4, shuffle=True, random_state=9)\n",
        "        val_acc_list = []\n",
        "        t = originalData.Mood\n",
        "        cross = 0\n",
        "        for train_index, test_index in skfold.split(np.zeros(len(t)), t):\n",
        "            train = originalData.iloc[train_index]\n",
        "            test = originalData.iloc[test_index]\n",
        "\n",
        "            train = train.reset_index(drop=True)\n",
        "            test = test.reset_index(drop=True)\n",
        "\n",
        "            bert_ensemble_model = BertEnsembleClassifier(BASE_DIR, mode=\"train\", cross=cross)\n",
        "            bert_ensemble_model.train(train, test, len(train.index), trainFromScratch=True)\n",
        "            print(\"After Training of the current fold - validation accuracy {}\".format(bert_ensemble_model.valid_accuracy_list))\n",
        "            val_acc_list.append(bert_ensemble_model.valid_accuracy_list)\n",
        "            cross = cross + 1\n",
        "\n",
        "            if not cross_Fold:\n",
        "              break\n",
        "\n",
        "\n",
        "        print(\"final list {}\".format(val_acc_list))\n",
        "        accSum = []\n",
        "        for foldAcc in val_acc_list:\n",
        "            accSum.append(max(foldAcc))\n",
        "\n",
        "        print(\"max list {}\".format(accSum))\n",
        "        print(\"average accuracy {}\".format(np.average(accSum)))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    else:\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}